{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/ecg_model\\\\30100.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants = glob('data/ecg_model/*.csv')\n",
    "participants[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\n",
    "    'ecg_model',\n",
    "    data_files = participants,\n",
    "    num_proc=8\n",
    ")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magics.execution import _format_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.2 µs ± 1.78 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1 , takes approx. 4h 24min 34s per epoch, divided over 8 workers = 33min 4s per epoch. Worst-case 11 epochs, it would take 6h 3min 47s in total. ( 16.2 µs per idx)\n",
      "21.4 µs ± 138 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10 , takes approx. 5h 49min 46s per epoch, divided over 8 workers = 43min 43s per epoch. Worst-case 11 epochs, it would take 8h 56s in total. ( 21.4 µs per idx)\n",
      "74.7 µs ± 635 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 100 , takes approx. 20h 19min 29s per epoch, divided over 8 workers = 2h 32min 26s per epoch. Worst-case 11 epochs, it would take 1d 3h 56min 48s in total. ( 74.7 µs per idx)\n",
      "584 µs ± 4.65 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1000 , takes approx. 6d 14h 54min 6s per epoch, divided over 8 workers = 19h 51min 45s per epoch. Worst-case 11 epochs, it would take 9d 2h 29min 23s in total. ( 584 µs per idx)\n",
      "5.89 ms ± 114 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10000 , takes approx. 66d 18h 41min 25s per epoch, divided over 8 workers = 8d 8h 20min 10s per epoch. Worst-case 11 epochs, it would take 91d 19h 41min 57s in total. ( 5.89 ms per idx)\n"
     ]
    }
   ],
   "source": [
    "workers = 8\n",
    "for window in [1, 10, 100, 1000, 10000]:\n",
    "    result = %timeit -o ds[0:0+window]['signal']\n",
    "    print(\"Training a model, with a dataset of length\", len(ds), \"and with a (sliding) window of\", window, \", takes approx.\", _format_time(result.average * len(ds)), \"per epoch, divided over\", workers, \"workers =\", _format_time((result.average * len(ds)) / workers),\"per epoch. Worst-case 11 epochs, it would take\", _format_time(((result.average * len(ds)) / workers) * 11),\"in total. (\", _format_time(result.average), \"per idx)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953 µs ± 6.15 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1 , takes approx. 10d 19h 25min 45s per epoch, divided over 8 workers = 1d 8h 25min 43s per epoch. Worst-case 11 epochs, it would take 14d 20h 42min 54s in total. ( 953 µs per idx)\n",
      "949 µs ± 4.07 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10 , takes approx. 10d 18h 22min 10s per epoch, divided over 8 workers = 1d 8h 17min 46s per epoch. Worst-case 11 epochs, it would take 14d 19h 15min 29s in total. ( 949 µs per idx)\n",
      "974 µs ± 2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 100 , takes approx. 11d 1h 8min 41s per epoch, divided over 8 workers = 1d 9h 8min 35s per epoch. Worst-case 11 epochs, it would take 15d 4h 34min 27s in total. ( 974 µs per idx)\n",
      "1.22 ms ± 4.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1000 , takes approx. 13d 20h 23min 48s per epoch, divided over 8 workers = 1d 17h 32min 58s per epoch. Worst-case 11 epochs, it would take 19d 1h 2min 44s in total. ( 1.22 ms per idx)\n",
      "4.07 ms ± 157 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10000 , takes approx. 46d 4h 44min 8s per epoch, divided over 8 workers = 5d 18h 35min 31s per epoch. Worst-case 11 epochs, it would take 63d 12h 30min 41s in total. ( 4.07 ms per idx)\n"
     ]
    }
   ],
   "source": [
    "workers = 8\n",
    "for window in [1, 10, 100, 1000, 10000]:\n",
    "    result = %timeit -o ds.select(range(0,0+window))['signal']\n",
    "    print(\"Training a model, with a dataset of length\", len(ds), \"and with a (sliding) window of\", window, \", takes approx.\", _format_time(result.average * len(ds)), \"per epoch, divided over\", workers, \"workers =\", _format_time((result.average * len(ds)) / workers),\"per epoch. Worst-case 11 epochs, it would take\", _format_time(((result.average * len(ds)) / workers) * 11),\"in total. (\", _format_time(result.average), \"per idx)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "ds_small = load_dataset(\n",
    "    'ecg_model',\n",
    "    data_files = participants[:10],\n",
    "    num_proc=8\n",
    ")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.5 µs ± 158 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1 , takes approx. 4h 13min 11s per epoch, divided over 8 workers = 31min 38s per epoch. Worst-case 11 epochs, it would take 5h 48min 8s in total. ( 15.5 µs per idx)\n",
      "20.9 µs ± 236 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10 , takes approx. 5h 41min 20s per epoch, divided over 8 workers = 42min 40s per epoch. Worst-case 11 epochs, it would take 7h 49min 20s in total. ( 20.9 µs per idx)\n",
      "75.4 µs ± 742 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 100 , takes approx. 20h 30min 29s per epoch, divided over 8 workers = 2h 33min 48s per epoch. Worst-case 11 epochs, it would take 1d 4h 11min 56s in total. ( 75.4 µs per idx)\n",
      "590 µs ± 5.72 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1000 , takes approx. 6d 16h 40min 2s per epoch, divided over 8 workers = 20h 5min per epoch. Worst-case 11 epochs, it would take 9d 4h 55min 2s in total. ( 590 µs per idx)\n",
      "6.05 ms ± 124 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10000 , takes approx. 68d 15h 1s per epoch, divided over 8 workers = 8d 13h 52min 30s per epoch. Worst-case 11 epochs, it would take 94d 8h 37min 32s in total. ( 6.05 ms per idx)\n"
     ]
    }
   ],
   "source": [
    "workers = 8\n",
    "for window in [1, 10, 100, 1000, 10000]:\n",
    "    result = %timeit -o ds_small[0:0+window]['signal']\n",
    "    print(\"Training a model, with a dataset of length\", len(ds), \"and with a (sliding) window of\", window, \", takes approx.\", _format_time(result.average * len(ds)), \"per epoch, divided over\", workers, \"workers =\", _format_time((result.average * len(ds)) / workers),\"per epoch. Worst-case 11 epochs, it would take\", _format_time(((result.average * len(ds)) / workers) * 11),\"in total. (\", _format_time(result.average), \"per idx)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 µs ± 191 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1 , takes approx. 4h 4min 22s per epoch, divided over 8 workers = 30min 32s per epoch. Worst-case 11 epochs, it would take 5h 36min in total. ( 15 µs per idx)\n",
      "20.5 µs ± 809 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10 , takes approx. 5h 35min 17s per epoch, divided over 8 workers = 41min 54s per epoch. Worst-case 11 epochs, it would take 7h 41min 1s in total. ( 20.5 µs per idx)\n",
      "71.6 µs ± 1.01 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 100 , takes approx. 19h 28min 22s per epoch, divided over 8 workers = 2h 26min 2s per epoch. Worst-case 11 epochs, it would take 1d 2h 46min 30s in total. ( 71.6 µs per idx)\n",
      "556 µs ± 5.87 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1000 , takes approx. 6d 7h 25min 20s per epoch, divided over 8 workers = 18h 55min 40s per epoch. Worst-case 11 epochs, it would take 8d 16h 12min 20s in total. ( 556 µs per idx)\n",
      "5.93 ms ± 106 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10000 , takes approx. 67d 5h 32min 56s per epoch, divided over 8 workers = 8d 9h 41min 37s per epoch. Worst-case 11 epochs, it would take 92d 10h 37min 48s in total. ( 5.93 ms per idx)\n"
     ]
    }
   ],
   "source": [
    "ds_list = []\n",
    "for participant in participants[:10]:\n",
    "    ds_list.append(load_dataset(\n",
    "        'ecg_model',\n",
    "        data_files = [participant],\n",
    "        num_proc=8\n",
    "    )['train'])\n",
    "\n",
    "workers = 8\n",
    "for ds_i in ds_list: \n",
    "    for window in [1, 10, 100, 1000, 10000]:\n",
    "        result = %timeit -o ds_i[0:0+window]['signal']\n",
    "        print(\"Training a model, with a dataset of length\", len(ds), \"and with a (sliding) window of\", window, \", takes approx.\", _format_time(result.average * len(ds)), \"per epoch, divided over\", workers, \"workers =\", _format_time((result.average * len(ds)) / workers),\"per epoch. Worst-case 11 epochs, it would take\", _format_time(((result.average * len(ds)) / workers) * 11),\"in total. (\", _format_time(result.average), \"per idx)\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\Admin\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\ecg_model\\93cfd00bb61081d43258126dc1793b3fad696e4b9dba6fdcadfff5c8a6712859 (last modified on Sun Mar 10 12:21:36 2024) since it couldn't be found locally at ecg_model, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "ds_extra_small = load_dataset(\n",
    "    'ecg_model',\n",
    "    data_files = participants[:1],\n",
    "    num_proc=8\n",
    ")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.1 µs ± 182 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1 , takes approx. 4h 6min 45s per epoch, divided over 8 workers = 30min 50s per epoch. Worst-case 11 epochs, it would take 5h 39min 18s in total. ( 15.1 µs per idx)\n",
      "20.5 µs ± 426 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10 , takes approx. 5h 34min 53s per epoch, divided over 8 workers = 41min 51s per epoch. Worst-case 11 epochs, it would take 7h 40min 28s in total. ( 20.5 µs per idx)\n",
      "72.4 µs ± 565 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 100 , takes approx. 19h 42min 52s per epoch, divided over 8 workers = 2h 27min 51s per epoch. Worst-case 11 epochs, it would take 1d 3h 6min 27s in total. ( 72.4 µs per idx)\n",
      "576 µs ± 13.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1000 , takes approx. 6d 12h 47min 42s per epoch, divided over 8 workers = 19h 35min 57s per epoch. Worst-case 11 epochs, it would take 8d 23h 35min 36s in total. ( 576 µs per idx)\n",
      "6.07 ms ± 162 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10000 , takes approx. 68d 18h 51min 46s per epoch, divided over 8 workers = 8d 14h 21min 28s per epoch. Worst-case 11 epochs, it would take 94d 13h 56min 11s in total. ( 6.07 ms per idx)\n"
     ]
    }
   ],
   "source": [
    "workers = 8\n",
    "for window in [1, 10, 100, 1000, 10000]:\n",
    "    result = %timeit -o ds_extra_small[0:0+window]['signal']\n",
    "    print(\"Training a model, with a dataset of length\", len(ds), \"and with a (sliding) window of\", window, \", takes approx.\", _format_time(result.average * len(ds)), \"per epoch, divided over\", workers, \"workers =\", _format_time((result.average * len(ds)) / workers),\"per epoch. Worst-case 11 epochs, it would take\", _format_time(((result.average * len(ds)) / workers) * 11),\"in total. (\", _format_time(result.average), \"per idx)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = load_from_disk('./data/combined')['fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.7 µs ± 927 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1 , takes approx. 1d 2h 19min 24s per epoch, divided over 8 workers = 3h 17min 25s per epoch. Worst-case 11 epochs, it would take 1d 12h 11min 40s in total. ( 96.7 µs per idx)\n",
      "105 µs ± 1.34 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10 , takes approx. 1d 4h 29min 50s per epoch, divided over 8 workers = 3h 33min 43s per epoch. Worst-case 11 epochs, it would take 1d 15h 11min 2s in total. ( 105 µs per idx)\n",
      "179 µs ± 796 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 100 , takes approx. 2d 45min 21s per epoch, divided over 8 workers = 6h 5min 40s per epoch. Worst-case 11 epochs, it would take 2d 19h 2min 21s in total. ( 179 µs per idx)\n",
      "867 µs ± 8.64 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1000 , takes approx. 9d 19h 58min 1s per epoch, divided over 8 workers = 1d 5h 29min 45s per epoch. Worst-case 11 epochs, it would take 13d 12h 27min 16s in total. ( 867 µs per idx)\n",
      "8.45 ms ± 177 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10000 , takes approx. 95d 20h 15min 36s per epoch, divided over 8 workers = 11d 23h 31min 57s per epoch. Worst-case 11 epochs, it would take 131d 18h 51min 27s in total. ( 8.45 ms per idx)\n"
     ]
    }
   ],
   "source": [
    "workers = 8\n",
    "for window in [1, 10, 100, 1000, 10000]:\n",
    "    result = %timeit -o combined[0:0+window]['signal']\n",
    "    print(\"Training a model, with a dataset of length\", len(ds), \"and with a (sliding) window of\", window, \", takes approx.\", _format_time(result.average * len(ds)), \"per epoch, divided over\", workers, \"workers =\", _format_time((result.average * len(ds)) / workers),\"per epoch. Worst-case 11 epochs, it would take\", _format_time(((result.average * len(ds)) / workers) * 11),\"in total. (\", _format_time(result.average), \"per idx)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_small = combined.select(range(86433000)) # for equal comparison with ds_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.4 µs ± 2.13 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1 , takes approx. 1d 2h 46min 9s per epoch, divided over 8 workers = 3h 20min 46s per epoch. Worst-case 11 epochs, it would take 1d 12h 48min 28s in total. ( 98.4 µs per idx)\n",
      "111 µs ± 4.36 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10 , takes approx. 1d 6h 5min 16s per epoch, divided over 8 workers = 3h 45min 39s per epoch. Worst-case 11 epochs, it would take 1d 17h 22min 14s in total. ( 111 µs per idx)\n",
      "187 µs ± 4.64 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 100 , takes approx. 2d 2h 50min 9s per epoch, divided over 8 workers = 6h 21min 16s per epoch. Worst-case 11 epochs, it would take 2d 21h 53min 57s in total. ( 187 µs per idx)\n",
      "903 µs ± 12.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 1000 , takes approx. 10d 5h 39min 16s per epoch, divided over 8 workers = 1d 6h 42min 24s per epoch. Worst-case 11 epochs, it would take 14d 1h 46min 30s in total. ( 903 µs per idx)\n",
      "8.45 ms ± 201 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Training a model, with a dataset of length 979678000 and with a (sliding) window of 10000 , takes approx. 95d 18h 15min 57s per epoch, divided over 8 workers = 11d 23h 16min 59s per epoch. Worst-case 11 epochs, it would take 131d 16h 6min 55s in total. ( 8.45 ms per idx)\n"
     ]
    }
   ],
   "source": [
    "workers = 8\n",
    "for window in [1, 10, 100, 1000, 10000]:\n",
    "    result = %timeit -o combined_small[0:0+window]['signal']\n",
    "    print(\"Training a model, with a dataset of length\", len(ds), \"and with a (sliding) window of\", window, \", takes approx.\", _format_time(result.average * len(ds)), \"per epoch, divided over\", workers, \"workers =\", _format_time((result.average * len(ds)) / workers),\"per epoch. Worst-case 11 epochs, it would take\", _format_time(((result.average * len(ds)) / workers) * 11),\"in total. (\", _format_time(result.average), \"per idx)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
