{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sia.transformers import as_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('csv', data_files='./data/ecg_model/30100.csv')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = ds[0:0+n]['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks, info = nk.ecg_peaks(window, sampling_rate=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG_Rate_Mean, ECG_Rate_STD\n",
    "meanHR = np.mean(nk.signal_rate(peaks, sampling_rate=1000))\n",
    "stdHR = np.std(nk.signal_rate(peaks, sampling_rate=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_indices = peaks[peaks['ECG_R_Peaks'] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.86730269, 0.91827365, 0.9718173 , 0.95877277, 0.99700897,\n",
       "        1.02564103, 1.001001  , 1.02040816, 1.04712042, 1.03305785,\n",
       "        1.11731844, 1.14416476, 1.00908174, 1.00806452, 1.01317123,\n",
       "        0.9487666 , 0.93632959, 0.93896714, 0.96061479]),\n",
       " 0.9956254016145706,\n",
       " 0.06392357793790138)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "periods=np.array([(peak_indices[i+1]-peak_indices[i])/1000 for i in range(0,len(peak_indices)-1)])\n",
    "frequency=1/periods\n",
    "meanfreq = np.mean(frequency)\n",
    "stdfreq = np.std(frequency)\n",
    "frequency, meanfreq, stdfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv = np.array([(peak_indices[i]-peak_indices[i-1])/1000 for i in range(1,len(peak_indices))])\n",
    "meanHRV=np.mean(hrv)\n",
    "stdHRV=np.std(hrv)\n",
    "rmsHRV=np.sqrt(np.mean(hrv**2))\n",
    "meanHRV, stdHRV, rmsHRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "def TINN(x:np.array):\n",
    "  \"\"\" Compute all the triangular interpolation to calculate the TINN scores. It also computes HRV index from an array x which contains \n",
    "      all the interbeats times for a given ECG signal.\n",
    "\n",
    "      The axis is divided in 2 parts respectively on the right and left of the abscissa of the maximum value of the gaussian distribution\n",
    "      The TINN score calculation is defined in the WESAD Dataset paper, to calculate it we needthe closest triangular interpolation \n",
    "      of the gaussian distribution of the interbeats times. The triangular interpolation is defined by 2 lines that meet at the maximum value\n",
    "      of the gaussian distribution and cross the x-axis in N on the first half of the x-axis and M on the second half of the x-axis. \n",
    "      Thus inside ]N;M[ the interpolation function != 0\n",
    "      Outside of ]N;M[ the interpolation function equals 0.\n",
    "  \"\"\"\n",
    "\n",
    "  kernel = stats.gaussian_kde(x) #Create an approximated kernel for gaussian distribution from the x array (interbeats times)\n",
    "  absi=np.linspace(np.min(x),np.max(x),len(x)) # Compute the x-axis of the interbeats distribution (from minimum interbeat time to maximum interbeat time)\n",
    "  val=kernel.evaluate(absi) # Fit the gaussian distribution to the created x-axis\n",
    "  ecart=absi[1]-absi[0] # Space between 2 values on the axis\n",
    "  maxind=np.argmax(val) # Select the index for which the gaussian distribution (val array) is maximum \n",
    "  max_pos=absi[maxind]  # Interbeat time (abscissa) for which the gaussian distribution is maximum\n",
    "  maxvalue=np.amax(val) # Max of the gaussian distribution\n",
    "  N_abs=absi[0:maxind+1] # First half of the x-axis\n",
    "  M_abs=absi[maxind:] # Second half of the x-axis\n",
    "  HRVindex=len(x)/maxvalue\n",
    "  err_N=[]\n",
    "  err_M=[]\n",
    "\n",
    "  for i in range(0,len(N_abs)-1):\n",
    "    N=N_abs[i]\n",
    "    slope=(maxvalue)/(max_pos-N)\n",
    "    D=val[0:maxind+1]\n",
    "    q=np.clip(slope*ecart*np.arange(-i,-i+maxind+1),0,None) #Triangular interpolation on the First half of the x-axis\n",
    "    diff=D-q \n",
    "    err=np.multiply(diff,diff)\n",
    "    err1=np.delete(err,-1)\n",
    "    err2=np.delete(err, 0)\n",
    "    errint=(err1+err2)/2\n",
    "    errtot=np.linalg.norm(errint) # Error area between the triangular interpolation and the gaussian distribution on the first half of the x-axis\n",
    "    err_N.append((errtot,N,N_abs,q))\n",
    "  \n",
    "  for i in range(1,len(M_abs)):\n",
    "    M=M_abs[i]\n",
    "    slope=(maxvalue)/(max_pos-M)\n",
    "    D=val[maxind:]\n",
    "    q=np.clip(slope*ecart*np.arange(-i,len(D)-i),0,None) #Triangular interpolation on the second half of the x-axis\n",
    "    diff=D-q\n",
    "    err=np.multiply(diff,diff)\n",
    "    err1=np.delete(err,-1)\n",
    "    err2=np.delete(err, 0)\n",
    "    errint=(err1+err2)/2\n",
    "    errtot=np.linalg.norm(errint) # Error area between the triangular interpolation and the gaussian distribution on the second half of the x-axis\n",
    "    err_M.append((errtot,M,M_abs,q))\n",
    "\n",
    "  return (err_N,err_M,absi,val,HRVindex)\n",
    "\n",
    "def best_TINN(x:np.array):\n",
    "  \"\"\"Select the best N and M that give the best triangular interpolation function approximation of the gaussian distrbution and return\n",
    "    N; M; the TINN score = M-N ; and the HRV index\n",
    "  \n",
    "  \"\"\"\n",
    "  err_N,err_M,_,_,HRVindex=TINN(x)\n",
    "  N=np.argmin(np.array(err_N,dtype=object)[:,0])\n",
    "  M=np.argmin(np.array(err_M,dtype=object)[:,0])\n",
    "  absN=err_N[N][1]\n",
    "  absM=err_M[M][1]\n",
    "  return float(absN),float(absM),float(absM-absN),HRVindex\n",
    "\n",
    "# _,_,T,HRVindex=best_TINN(hrv)\n",
    "# T, HRVindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_compare_NN50(x,i):\n",
    "  \"\"\"Count the number of HRV intervals differing more than 50 ms for a given HRV interval x[i]\n",
    "  \n",
    "  \"\"\"\n",
    "  ref=x[i]\n",
    "  k=0\n",
    "  diff=np.absolute(x-ref)\n",
    "  k+=np.sum(np.where(diff>0.05,1,0))\n",
    "  return k \n",
    "\n",
    "def compare_NN50(x):\n",
    "  \"\"\" Returns the number and percentage of HRV intervals differing more than 50ms for all intervals\n",
    "  \n",
    "  \"\"\"\n",
    "  k=0\n",
    "  for i in range(0,len(x)):\n",
    "    k+=num_compare_NN50(x,i)\n",
    "  if k==0:\n",
    "    k=1\n",
    "  return k,(k/(len(x)*len(x)))\n",
    "\n",
    "# num50,p50=compare_NN50(hrv)\n",
    "# num50, p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_features_ecg(x):\n",
    "  \"\"\" Returns frequential features of the Heart Rate Variability signal (interbeats times) by computing FFT, to compute the Fouriers \n",
    "  Frequencies the mean of the Heart Rate variability is used as sampling period  \n",
    "  \"\"\"\n",
    "  mean=np.mean(x)\n",
    "  yf=np.array(scipy.fft.fft(x-mean))\n",
    "  xf=scipy.fft.fftfreq(len(x),mean)[0:len(x)//2]\n",
    "  psd=(2/len(yf))*np.abs(yf)[0:len(x)//2]\n",
    "  fmean=np.mean(xf)\n",
    "  fstd=np.std(xf)\n",
    "  sumpsd=np.sum(psd)\n",
    "  return fmean,fstd,sumpsd\n",
    "\n",
    "# fmean,fstd,sumpsd=get_freq_features_ecg(hrv)\n",
    "# fmean,fstd, sumpsd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV_MeanNN</th>\n",
       "      <th>HRV_SDNN</th>\n",
       "      <th>HRV_SDANN1</th>\n",
       "      <th>HRV_SDNNI1</th>\n",
       "      <th>HRV_SDANN2</th>\n",
       "      <th>HRV_SDNNI2</th>\n",
       "      <th>HRV_SDANN5</th>\n",
       "      <th>HRV_SDNNI5</th>\n",
       "      <th>HRV_RMSSD</th>\n",
       "      <th>HRV_SDSD</th>\n",
       "      <th>...</th>\n",
       "      <th>HRV_SampEn</th>\n",
       "      <th>HRV_ShanEn</th>\n",
       "      <th>HRV_FuzzyEn</th>\n",
       "      <th>HRV_MSEn</th>\n",
       "      <th>HRV_CMSEn</th>\n",
       "      <th>HRV_RCMSEn</th>\n",
       "      <th>HRV_CD</th>\n",
       "      <th>HRV_HFD</th>\n",
       "      <th>HRV_KFD</th>\n",
       "      <th>HRV_LZC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1008.473684</td>\n",
       "      <td>65.574697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.192182</td>\n",
       "      <td>46.059495</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>1.254404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.525146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.373195</td>\n",
       "      <td>0.894301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    HRV_MeanNN   HRV_SDNN  HRV_SDANN1  HRV_SDNNI1  HRV_SDANN2  HRV_SDNNI2  \\\n",
       "0  1008.473684  65.574697         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   HRV_SDANN5  HRV_SDNNI5  HRV_RMSSD   HRV_SDSD  ...  HRV_SampEn  HRV_ShanEn  \\\n",
       "0         NaN         NaN  45.192182  46.059495  ...         inf    4.247928   \n",
       "\n",
       "   HRV_FuzzyEn  HRV_MSEn  HRV_CMSEn  HRV_RCMSEn    HRV_CD  HRV_HFD   HRV_KFD  \\\n",
       "0     1.254404       NaN        NaN         NaN  1.525146      NaN  1.373195   \n",
       "\n",
       "    HRV_LZC  \n",
       "0  0.894301  \n",
       "\n",
       "[1 rows x 82 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrv_indices = nk.hrv(peaks, sampling_rate=1000)\n",
    "hrv_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanHR</th>\n",
       "      <th>stdHR</th>\n",
       "      <th>TINN</th>\n",
       "      <th>HRVindex</th>\n",
       "      <th>%NN50</th>\n",
       "      <th>pnn50</th>\n",
       "      <th>meanHRV</th>\n",
       "      <th>stdHRV</th>\n",
       "      <th>rmsHRV</th>\n",
       "      <th>Mean Fourier Frequencies</th>\n",
       "      <th>STD Fourier Frequencies</th>\n",
       "      <th>Sum PSD components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.72544</td>\n",
       "      <td>3.738671</td>\n",
       "      <td>132.8125</td>\n",
       "      <td>3.229072</td>\n",
       "      <td>204</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>1.008474</td>\n",
       "      <td>0.063826</td>\n",
       "      <td>1.010491</td>\n",
       "      <td>0.208757</td>\n",
       "      <td>0.134752</td>\n",
       "      <td>0.186687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     meanHR     stdHR      TINN  HRVindex  %NN50      pnn50   meanHRV  \\\n",
       "0  59.72544  3.738671  132.8125  3.229072    204  26.315789  1.008474   \n",
       "\n",
       "     stdHRV    rmsHRV  Mean Fourier Frequencies  STD Fourier Frequencies  \\\n",
       "0  0.063826  1.010491                  0.208757                 0.134752   \n",
       "\n",
       "   Sum PSD components  \n",
       "0            0.186687  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/Edouard99/Stress_Detection_ECG/tree/main\n",
    "pd.DataFrame({\n",
    "    'meanHR': meanHR,\n",
    "    'stdHR': stdHR,\n",
    "    'TINN': hrv_indices['HRV_TINN'],\n",
    "    'HRVindex': HRVindex,\n",
    "    '%NN50': num50,\n",
    "    'pnn50': hrv_indices['HRV_pNN50'],\n",
    "    'meanHRV': meanHRV,\n",
    "    'stdHRV': stdHRV,\n",
    "    'rmsHRV': rmsHRV,\n",
    "    'Mean Fourier Frequencies': fmean,\n",
    "    'STD Fourier Frequencies': fstd,\n",
    "    'Sum PSD components': sumpsd\n",
    "}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV_ULF</th>\n",
       "      <th>HRV_VLF</th>\n",
       "      <th>HRV_LF</th>\n",
       "      <th>HRV_HF</th>\n",
       "      <th>HRV_VHF</th>\n",
       "      <th>HRV_TP</th>\n",
       "      <th>HRV_LFHF</th>\n",
       "      <th>HRV_LFn</th>\n",
       "      <th>HRV_HFn</th>\n",
       "      <th>HRV_LnHF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.018271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.905738</td>\n",
       "      <td>-4.101447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HRV_ULF  HRV_VLF  HRV_LF    HRV_HF   HRV_VHF    HRV_TP  HRV_LFHF  HRV_LFn  \\\n",
       "0      NaN      NaN     NaN  0.016549  0.001722  0.018271       NaN      NaN   \n",
       "\n",
       "    HRV_HFn  HRV_LnHF  \n",
       "0  0.905738 -4.101447  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = nk.hrv_frequency(\n",
    "    peaks, \n",
    "    sampling_rate=1000,\n",
    "    ulf=[0.01,0.04],\n",
    "    lf=[0.04,0.15],\n",
    "    hf=[0.15,0.4],\n",
    "    vhf=[0.4,1]\n",
    ")\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_power = np.nansum([frequencies['HRV_ULF'], frequencies['HRV_LF'], frequencies['HRV_HF'], frequencies['HRV_VHF']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>μHR</th>\n",
       "      <th>σHR</th>\n",
       "      <th>μHRV</th>\n",
       "      <th>σHRV</th>\n",
       "      <th>NN50</th>\n",
       "      <th>pNN50</th>\n",
       "      <th>TINN</th>\n",
       "      <th>rmsHRV</th>\n",
       "      <th>ULF</th>\n",
       "      <th>LF</th>\n",
       "      <th>HF</th>\n",
       "      <th>UHF</th>\n",
       "      <th>LF_HF_Ratio</th>\n",
       "      <th>total_power</th>\n",
       "      <th>relative_power_ulf</th>\n",
       "      <th>relative_power_lf</th>\n",
       "      <th>relative_power_hf</th>\n",
       "      <th>relative_power_vhf</th>\n",
       "      <th>LF_norm</th>\n",
       "      <th>HF_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.72544</td>\n",
       "      <td>3.738671</td>\n",
       "      <td>1.008474</td>\n",
       "      <td>0.063826</td>\n",
       "      <td>204</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>132.8125</td>\n",
       "      <td>1.010491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.573825</td>\n",
       "      <td>9.426175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        μHR       σHR      μHRV      σHRV  NN50      pNN50      TINN  \\\n",
       "0  59.72544  3.738671  1.008474  0.063826   204  26.315789  132.8125   \n",
       "\n",
       "     rmsHRV  ULF  LF        HF       UHF  LF_HF_Ratio  total_power  \\\n",
       "0  1.010491  NaN NaN  0.016549  0.001722          NaN     0.018271   \n",
       "\n",
       "   relative_power_ulf  relative_power_lf  relative_power_hf  \\\n",
       "0                 NaN                NaN          90.573825   \n",
       "\n",
       "   relative_power_vhf  LF_norm  HF_norm  \n",
       "0            9.426175      NaN      NaN  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://dl-acm-org.vu-nl.idm.oclc.org/doi/epdf/10.1145/3242969.3242985\n",
    "pd.DataFrame({\n",
    "    'μHR': meanHR,\n",
    "    'σHR': stdHR,\n",
    "    'μHRV': meanHRV,\n",
    "    'σHRV': stdHRV,\n",
    "    'NN50': num50, \n",
    "    'pNN50': hrv_indices['HRV_pNN50'],\n",
    "    'TINN': hrv_indices['HRV_TINN'],\n",
    "    'rmsHRV': rmsHRV,\n",
    "    'ULF': frequencies['HRV_ULF'],\n",
    "    'LF': frequencies['HRV_LF'],\n",
    "    'HF': frequencies['HRV_HF'],\n",
    "    'UHF': frequencies['HRV_VHF'],\n",
    "    'LF_HF_Ratio': frequencies['HRV_LF'] / frequencies['HRV_HF'],\n",
    "    'total_power': total_power,\n",
    "    'relative_power_ulf': (frequencies['HRV_ULF'] / total_power) * 100,\n",
    "    'relative_power_lf': (frequencies['HRV_LF'] / total_power) * 100,\n",
    "    'relative_power_hf': (frequencies['HRV_HF'] / total_power) * 100,\n",
    "    'relative_power_vhf': (frequencies['HRV_VHF'] / total_power) * 100,\n",
    "    'LF_norm': np.nan,  ## Can only be normalised after all the LF and HF are calculated\n",
    "    'HF_norm': np.nan,  ## Can only be normalised after all the LF and HF are calculated\n",
    "}, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “heart rate” can be described as a true rate in beats per minute (HR) or as the RR interval in milliseconds. \n",
    "The RR interval is the time elapsed between two successive R waves of the QRS signal on the electrocardiogram\n",
    "“Heart rate variability” has become the conventionally accepted term to describe variations of both instantaneous heart rate and RR intervals.\n",
    "\n",
    "The RR interval and HR are hyperbolically related (HR x RR interval = 60000; see figure 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HRV_MeanNN', 'HRV_SDNN', 'HRV_SDANN1', 'HRV_SDNNI1', 'HRV_SDANN2',\n",
       "       'HRV_SDNNI2', 'HRV_SDANN5', 'HRV_SDNNI5', 'HRV_RMSSD', 'HRV_SDSD',\n",
       "       'HRV_CVNN', 'HRV_CVSD', 'HRV_MedianNN', 'HRV_MadNN', 'HRV_MCVNN',\n",
       "       'HRV_IQRNN', 'HRV_SDRMSSD', 'HRV_Prc20NN', 'HRV_Prc80NN', 'HRV_pNN50',\n",
       "       'HRV_pNN20', 'HRV_MinNN', 'HRV_MaxNN', 'HRV_HTI', 'HRV_TINN', 'HRV_ULF',\n",
       "       'HRV_VLF', 'HRV_LF', 'HRV_HF', 'HRV_VHF', 'HRV_TP', 'HRV_LFHF',\n",
       "       'HRV_LFn', 'HRV_HFn', 'HRV_LnHF', 'HRV_SD1', 'HRV_SD2', 'HRV_SD1SD2',\n",
       "       'HRV_S', 'HRV_CSI', 'HRV_CVI', 'HRV_CSI_Modified', 'HRV_PIP',\n",
       "       'HRV_IALS', 'HRV_PSS', 'HRV_PAS', 'HRV_GI', 'HRV_SI', 'HRV_AI',\n",
       "       'HRV_PI', 'HRV_C1d', 'HRV_C1a', 'HRV_SD1d', 'HRV_SD1a', 'HRV_C2d',\n",
       "       'HRV_C2a', 'HRV_SD2d', 'HRV_SD2a', 'HRV_Cd', 'HRV_Ca', 'HRV_SDNNd',\n",
       "       'HRV_SDNNa', 'HRV_DFA_alpha1', 'HRV_MFDFA_alpha1_Width',\n",
       "       'HRV_MFDFA_alpha1_Peak', 'HRV_MFDFA_alpha1_Mean',\n",
       "       'HRV_MFDFA_alpha1_Max', 'HRV_MFDFA_alpha1_Delta',\n",
       "       'HRV_MFDFA_alpha1_Asymmetry', 'HRV_MFDFA_alpha1_Fluctuation',\n",
       "       'HRV_MFDFA_alpha1_Increment', 'HRV_ApEn', 'HRV_SampEn', 'HRV_ShanEn',\n",
       "       'HRV_FuzzyEn', 'HRV_MSEn', 'HRV_CMSEn', 'HRV_RCMSEn', 'HRV_CD',\n",
       "       'HRV_HFD', 'HRV_KFD', 'HRV_LZC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrv_indices.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_window = 20 * 1000\n",
    "sampling_rate = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('./data/ecg_model/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 8344000 examples [00:05, 1466368.61 examples/s]\n",
      "Generating train split: 8174000 examples [00:05, 1501210.86 examples/s]\n",
      "Generating train split: 9684000 examples [00:06, 1472055.45 examples/s]\n",
      "Generating train split: 7842000 examples [00:05, 1432841.18 examples/s]\n",
      "Generating train split: 7729000 examples [00:05, 1457442.11 examples/s]\n",
      "Generating train split: 7737000 examples [00:05, 1489999.87 examples/s]\n",
      "Generating train split: 9241000 examples [00:06, 1451260.84 examples/s]\n",
      "Generating train split: 8718000 examples [00:05, 1457704.18 examples/s]\n",
      "Generating train split: 10272000 examples [00:07, 1446480.51 examples/s]\n",
      "Generating train split: 8212000 examples [00:05, 1435243.77 examples/s]\n",
      "Generating train split: 7871000 examples [00:05, 1483389.34 examples/s]\n",
      "Generating train split: 8530000 examples [00:05, 1462965.23 examples/s]\n",
      "Generating train split: 7112000 examples [00:05, 1366895.17 examples/s]\n",
      "Generating train split: 8624000 examples [00:05, 1467109.58 examples/s]\n",
      "Generating train split: 9975000 examples [00:06, 1477951.14 examples/s]\n",
      "Generating train split: 8185000 examples [00:05, 1462167.99 examples/s]\n",
      "Generating train split: 8849000 examples [00:06, 1377299.48 examples/s]\n",
      "Generating train split: 7552000 examples [00:05, 1503259.78 examples/s]\n",
      "Generating train split: 7297000 examples [00:05, 1455901.99 examples/s]\n",
      "Generating train split: 7482000 examples [00:05, 1485429.09 examples/s]\n",
      "Generating train split: 7726000 examples [00:05, 1489459.34 examples/s]\n",
      "Generating train split: 8568000 examples [00:06, 1379037.95 examples/s]\n",
      "Generating train split: 7769000 examples [00:05, 1520014.07 examples/s]\n",
      "Generating train split: 8439000 examples [00:05, 1457590.03 examples/s]\n",
      "Generating train split: 7259000 examples [00:04, 1491311.56 examples/s]\n",
      "Generating train split: 8211000 examples [00:05, 1463607.96 examples/s]\n",
      "Generating train split: 7726000 examples [00:05, 1493661.93 examples/s]\n",
      "Generating train split: 7106000 examples [00:04, 1475070.28 examples/s]\n",
      "Generating train split: 7875000 examples [00:05, 1488791.99 examples/s]\n",
      "Generating train split: 7772000 examples [00:05, 1501820.19 examples/s]\n",
      "Generating train split: 7589000 examples [00:05, 1467642.59 examples/s]\n",
      "Generating train split: 8139000 examples [00:05, 1405535.35 examples/s]\n",
      "Generating train split: 7324000 examples [00:04, 1491125.02 examples/s]\n",
      "Generating train split: 7880000 examples [00:05, 1524300.73 examples/s]\n",
      "Generating train split: 7873000 examples [00:05, 1508546.63 examples/s]\n",
      "Generating train split: 7462000 examples [00:05, 1470138.58 examples/s]\n",
      "Generating train split: 8370000 examples [00:05, 1490130.45 examples/s]\n",
      "Generating train split: 6906000 examples [00:05, 1337304.95 examples/s]\n",
      "Generating train split: 7847000 examples [00:05, 1477356.91 examples/s]\n",
      "Generating train split: 7861000 examples [00:05, 1472996.03 examples/s]\n",
      "Generating train split: 7451000 examples [00:05, 1483986.81 examples/s]\n",
      "Generating train split: 8050000 examples [00:05, 1496354.58 examples/s]\n",
      "Generating train split: 8025000 examples [00:05, 1490679.10 examples/s]\n",
      "Generating train split: 8035000 examples [00:05, 1491134.12 examples/s]\n",
      "Generating train split: 8123000 examples [00:05, 1488028.41 examples/s]\n",
      "Generating train split: 8309000 examples [00:05, 1403769.97 examples/s]\n",
      "Generating train split: 7275000 examples [00:04, 1508421.59 examples/s]\n",
      "Generating train split: 7870000 examples [00:05, 1502698.85 examples/s]\n",
      "Generating train split: 6866000 examples [00:04, 1499959.96 examples/s]\n",
      "Generating train split: 7985000 examples [00:05, 1502838.48 examples/s]\n",
      "Generating train split: 7835000 examples [00:05, 1468424.33 examples/s]\n",
      "Generating train split: 7633000 examples [00:05, 1522617.59 examples/s]\n",
      "Generating train split: 7805000 examples [00:05, 1446401.63 examples/s]\n",
      "Generating train split: 6100000 examples [00:04, 1489852.21 examples/s]\n",
      "Generating train split: 7232000 examples [00:05, 1443994.21 examples/s]\n",
      "Generating train split: 8089000 examples [00:05, 1512219.00 examples/s]\n",
      "Generating train split: 7762000 examples [00:05, 1470688.52 examples/s]\n",
      "Generating train split: 7241000 examples [00:04, 1481386.23 examples/s]\n",
      "Generating train split: 7997000 examples [00:05, 1490251.44 examples/s]\n",
      "Generating train split: 7050000 examples [00:04, 1476435.12 examples/s]\n",
      "Generating train split: 7238000 examples [00:04, 1472806.34 examples/s]\n",
      "Generating train split: 7012000 examples [00:04, 1495921.03 examples/s]\n",
      "Generating train split: 8143000 examples [00:05, 1439639.98 examples/s]\n",
      "Generating train split: 7419000 examples [00:05, 1474011.29 examples/s]\n",
      "Generating train split: 7902000 examples [00:05, 1458659.39 examples/s]\n",
      "Generating train split: 7325000 examples [00:05, 1445620.10 examples/s]\n",
      "Generating train split: 8207000 examples [00:05, 1448743.51 examples/s]\n",
      "Generating train split: 7823000 examples [00:05, 1385221.12 examples/s]\n",
      "Generating train split: 7397000 examples [00:05, 1251755.69 examples/s]\n",
      "Generating train split: 7013000 examples [00:04, 1482913.27 examples/s]\n",
      "Generating train split: 7347000 examples [00:04, 1479175.68 examples/s]\n",
      "Generating train split: 6959000 examples [00:04, 1506592.68 examples/s]\n",
      "Generating train split: 8164000 examples [00:05, 1476776.78 examples/s]\n",
      "Generating train split: 6658000 examples [00:04, 1467507.06 examples/s]\n",
      "Generating train split: 7479000 examples [00:05, 1443341.87 examples/s]\n",
      "Generating train split: 7982000 examples [00:05, 1496327.83 examples/s]\n",
      "Generating train split: 7542000 examples [00:05, 1450192.04 examples/s]\n",
      "Generating train split: 7413000 examples [00:05, 1346172.63 examples/s]\n",
      "Generating train split: 7744000 examples [00:05, 1474406.64 examples/s]\n",
      "Generating train split: 7381000 examples [00:05, 1406210.97 examples/s]\n",
      "Generating train split: 7376000 examples [00:04, 1519077.36 examples/s]\n",
      "Generating train split: 8129000 examples [00:05, 1503275.05 examples/s]\n",
      "Generating train split: 7346000 examples [00:04, 1513965.52 examples/s]\n",
      "Generating train split: 6913000 examples [00:04, 1493533.05 examples/s]\n",
      "Generating train split: 6830000 examples [00:04, 1419854.70 examples/s]\n",
      "Generating train split: 7656000 examples [00:04, 1637960.24 examples/s]\n",
      "Generating train split: 7192000 examples [00:04, 1674413.66 examples/s]\n",
      "Generating train split: 7583000 examples [00:04, 1719180.72 examples/s]\n",
      "Generating train split: 7588000 examples [00:04, 1730115.18 examples/s]\n",
      "Generating train split: 7237000 examples [00:04, 1725925.31 examples/s]\n",
      "Generating train split: 6941000 examples [00:04, 1706032.05 examples/s]\n",
      "Generating train split: 7337000 examples [00:04, 1628528.71 examples/s]\n",
      "Generating train split: 7641000 examples [00:04, 1621801.64 examples/s]\n",
      "Generating train split: 7662000 examples [00:05, 1440573.43 examples/s]\n",
      "Generating train split: 7176000 examples [00:04, 1575591.15 examples/s]\n",
      "Generating train split: 7023000 examples [00:04, 1672067.28 examples/s]\n",
      "Generating train split: 7087000 examples [00:04, 1665360.29 examples/s]\n",
      "Generating train split: 7326000 examples [00:04, 1614882.27 examples/s]\n",
      "Generating train split: 7063000 examples [00:04, 1646829.20 examples/s]\n",
      "Generating train split: 7312000 examples [00:04, 1663496.43 examples/s]\n",
      "Generating train split: 7828000 examples [00:04, 1656060.63 examples/s]\n",
      "Generating train split: 7112000 examples [00:04, 1695327.55 examples/s]\n",
      "Generating train split: 7371000 examples [00:04, 1659743.77 examples/s]\n",
      "Generating train split: 7289000 examples [00:04, 1687448.56 examples/s]\n",
      "Generating train split: 7278000 examples [00:04, 1655772.49 examples/s]\n",
      "Generating train split: 7350000 examples [00:04, 1636580.77 examples/s]\n",
      "Generating train split: 7243000 examples [00:04, 1710614.52 examples/s]\n",
      "Generating train split: 7261000 examples [00:04, 1704653.67 examples/s]\n",
      "Generating train split: 7185000 examples [00:04, 1714317.18 examples/s]\n",
      "Generating train split: 7296000 examples [00:04, 1662522.64 examples/s]\n",
      "Generating train split: 7971000 examples [00:04, 1692304.08 examples/s]\n",
      "Generating train split: 7059000 examples [00:04, 1692786.37 examples/s]\n",
      "Generating train split: 8142000 examples [00:04, 1681051.25 examples/s]\n",
      "Generating train split: 9622000 examples [00:05, 1661745.15 examples/s]\n",
      "Generating train split: 7678000 examples [00:04, 1639045.09 examples/s]\n",
      "Generating train split: 9173000 examples [00:05, 1672644.04 examples/s]\n",
      "Generating train split: 7695000 examples [00:04, 1616964.01 examples/s]\n",
      "Generating train split: 8540000 examples [00:05, 1687558.84 examples/s]\n",
      "Generating train split: 7206000 examples [00:04, 1604000.70 examples/s]\n",
      "Generating train split: 7717000 examples [00:04, 1631243.36 examples/s]\n",
      "Generating train split: 7405000 examples [00:04, 1697976.34 examples/s]\n",
      "Generating train split: 7075000 examples [00:04, 1629612.58 examples/s]\n",
      "Generating train split: 7249000 examples [00:04, 1619474.23 examples/s]\n",
      "Generating train split: 7652000 examples [00:05, 1496893.43 examples/s]\n",
      "Generating train split: 7203000 examples [00:04, 1626922.50 examples/s]\n",
      "Generating train split: 7955000 examples [00:04, 1612877.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    dataset = load_dataset('csv', data_files=file)['train']\n",
    "    dataframes = []\n",
    "    for i in range(len(dataset) // n_window):\n",
    "        try:\n",
    "            start_idx = i * n_window\n",
    "            sample = dataset[start_idx:start_idx+n_window]\n",
    "            signal = sample['signal']\n",
    "            label = stats.mode(sample['label'])[0]\n",
    "\n",
    "            peaks, _ = nk.ecg_peaks(signal, sampling_rate=sampling_rate)\n",
    "            peaks_indices = peaks[peaks['ECG_R_Peaks'] == 1].index\n",
    "\n",
    "            ## HR\n",
    "            signal_rate = nk.signal_rate(peaks, sampling_rate=sampling_rate)\n",
    "            mean_hr = np.mean(signal_rate)\n",
    "            std_hr = np.std(signal_rate)\n",
    "\n",
    "            ## Frequencies\n",
    "            periods = np.array([(peaks_indices[i+1]-peaks_indices[i])/sampling_rate for i in range(0,len(peaks_indices)-1)])\n",
    "            frequency = 1 / periods\n",
    "            mean_freq = np.mean(frequency)\n",
    "            std_freq = np.std(frequency)\n",
    "            mean_f, std_f, sum_psd = get_freq_features_ecg(periods)\n",
    "            \n",
    "            ## HRV\n",
    "            hrv = np.array([(peaks_indices[i]-peaks_indices[i-1])/sampling_rate for i in range(1,len(peaks_indices))])\n",
    "            mean_hrv = np.mean(hrv)\n",
    "            std_hrv = np.std(hrv)\n",
    "            rms_hrv = np.sqrt(np.mean(hrv**2))\n",
    "            _, _, _, hrv_index = best_TINN(hrv)\n",
    "\n",
    "            ## %NN50\n",
    "            NN50, pNN50 = compare_NN50(hrv)\n",
    "\n",
    "            ## Power\n",
    "            frequencies = nk.hrv_frequency(\n",
    "                peaks, \n",
    "                sampling_rate=sampling_rate,\n",
    "                ulf=[0.01,0.04],\n",
    "                lf=[0.04,0.15],\n",
    "                hf=[0.15,0.4],\n",
    "                vhf=[0.4,1]\n",
    "            )\n",
    "            total_power = np.nansum([frequencies['HRV_ULF'], frequencies['HRV_LF'], frequencies['HRV_HF'], frequencies['HRV_VHF']])\n",
    "\n",
    "            ## Dataframe\n",
    "            df = nk.hrv(peaks, sampling_rate=sampling_rate)\n",
    "            df['label'] = label\n",
    "            df['mean_hr'] = mean_hr\n",
    "            df['std_hr'] = std_hr\n",
    "            df['hrv_index'] = hrv_index\n",
    "            df['nn50'] = NN50\n",
    "            df['mean_hrv'] = mean_hrv\n",
    "            df['std_hrv'] = std_hrv\n",
    "            df['rms_hrv'] = rms_hrv\n",
    "            df['mean_fourier_frequencies'] = mean_f\n",
    "            df['std_fourier_frequencies'] = std_f\n",
    "            df['sum_psd'] = sum_psd\n",
    "            df['ulf'] = frequencies['HRV_ULF']\n",
    "            df['lf'] = frequencies['HRV_LF']\n",
    "            df['hf'] = frequencies['HRV_HF']\n",
    "            df['uhf'] = frequencies['HRV_VHF']\n",
    "            df['lf_hf_ratio'] = frequencies['HRV_LF'] / frequencies['HRV_HF']\n",
    "            df['total_power'] = total_power\n",
    "            df['relative_power_ulf'] = (frequencies['HRV_ULF'] / total_power) * 100\n",
    "            df['relative_power_lf'] = (frequencies['HRV_LF'] / total_power) * 100\n",
    "            df['relative_power_hf'] = (frequencies['HRV_HF'] / total_power) * 100\n",
    "            df['relative_power_vhf'] = (frequencies['HRV_VHF'] / total_power) * 100\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            continue\n",
    "        \n",
    "    result = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    stem = Path(file).stem\n",
    "    result.to_csv(f'./data/ecg_features/{stem}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'HRV_MeanNN',\n",
      "'HRV_SDNN',\n",
      "'HRV_SDANN1',\n",
      "'HRV_SDNNI1',\n",
      "'HRV_SDANN2',\n",
      "'HRV_SDNNI2',\n",
      "'HRV_SDANN5',\n",
      "'HRV_SDNNI5',\n",
      "'HRV_RMSSD',\n",
      "'HRV_SDSD',\n",
      "'HRV_CVNN',\n",
      "'HRV_CVSD',\n",
      "'HRV_MedianNN',\n",
      "'HRV_MadNN',\n",
      "'HRV_MCVNN',\n",
      "'HRV_IQRNN',\n",
      "'HRV_SDRMSSD',\n",
      "'HRV_Prc20NN',\n",
      "'HRV_Prc80NN',\n",
      "'HRV_pNN50',\n",
      "'HRV_pNN20',\n",
      "'HRV_MinNN',\n",
      "'HRV_MaxNN',\n",
      "'HRV_HTI',\n",
      "'HRV_TINN',\n",
      "'HRV_ULF',\n",
      "'HRV_VLF',\n",
      "'HRV_LF',\n",
      "'HRV_HF',\n",
      "'HRV_VHF',\n",
      "'HRV_TP',\n",
      "'HRV_LFHF',\n",
      "'HRV_LFn',\n",
      "'HRV_HFn',\n",
      "'HRV_LnHF',\n",
      "'HRV_SD1',\n",
      "'HRV_SD2',\n",
      "'HRV_SD1SD2',\n",
      "'HRV_S',\n",
      "'HRV_CSI',\n",
      "'HRV_CVI',\n",
      "'HRV_CSI_Modified',\n",
      "'HRV_PIP',\n",
      "'HRV_IALS',\n",
      "'HRV_PSS',\n",
      "'HRV_PAS',\n",
      "'HRV_GI',\n",
      "'HRV_SI',\n",
      "'HRV_AI',\n",
      "'HRV_PI',\n",
      "'HRV_C1d',\n",
      "'HRV_C1a',\n",
      "'HRV_SD1d',\n",
      "'HRV_SD1a',\n",
      "'HRV_C2d',\n",
      "'HRV_C2a',\n",
      "'HRV_SD2d',\n",
      "'HRV_SD2a',\n",
      "'HRV_Cd',\n",
      "'HRV_Ca',\n",
      "'HRV_SDNNd',\n",
      "'HRV_SDNNa',\n",
      "'HRV_DFA_alpha1',\n",
      "'HRV_MFDFA_alpha1_Width',\n",
      "'HRV_MFDFA_alpha1_Peak',\n",
      "'HRV_MFDFA_alpha1_Mean',\n",
      "'HRV_MFDFA_alpha1_Max',\n",
      "'HRV_MFDFA_alpha1_Delta',\n",
      "'HRV_MFDFA_alpha1_Asymmetry',\n",
      "'HRV_MFDFA_alpha1_Fluctuation',\n",
      "'HRV_MFDFA_alpha1_Increment',\n",
      "'HRV_ApEn',\n",
      "'HRV_SampEn',\n",
      "'HRV_ShanEn',\n",
      "'HRV_FuzzyEn',\n",
      "'HRV_MSEn',\n",
      "'HRV_CMSEn',\n",
      "'HRV_RCMSEn',\n",
      "'HRV_CD',\n",
      "'HRV_HFD',\n",
      "'HRV_KFD',\n",
      "'HRV_LZC',\n",
      "'label',\n",
      "'mean_hr',\n",
      "'std_hr',\n",
      "'hrv_index',\n",
      "'nn50',\n",
      "'mean_hrv',\n",
      "'std_hrv',\n",
      "'rms_hrv',\n",
      "'mean_fourier_frequencies',\n",
      "'std_fourier_frequencies',\n",
      "'sum_psd',\n",
      "'ulf',\n",
      "'lf',\n",
      "'hf',\n",
      "'uhf',\n",
      "'lf_hf_ratio',\n",
      "'total_power',\n",
      "'relative_power_ulf',\n",
      "'relative_power_lf',\n",
      "'relative_power_hf',\n",
      "'relative_power_vhf',\n",
      "'HRV_MeanNN': Value('float64'),\n",
      "'HRV_SDNN': Value('float64'),\n",
      "'HRV_SDANN1': Value('float64'),\n",
      "'HRV_SDNNI1': Value('float64'),\n",
      "'HRV_SDANN2': Value('float64'),\n",
      "'HRV_SDNNI2': Value('float64'),\n",
      "'HRV_SDANN5': Value('float64'),\n",
      "'HRV_SDNNI5': Value('float64'),\n",
      "'HRV_RMSSD': Value('float64'),\n",
      "'HRV_SDSD': Value('float64'),\n",
      "'HRV_CVNN': Value('float64'),\n",
      "'HRV_CVSD': Value('float64'),\n",
      "'HRV_MedianNN': Value('float64'),\n",
      "'HRV_MadNN': Value('float64'),\n",
      "'HRV_MCVNN': Value('float64'),\n",
      "'HRV_IQRNN': Value('float64'),\n",
      "'HRV_SDRMSSD': Value('float64'),\n",
      "'HRV_Prc20NN': Value('float64'),\n",
      "'HRV_Prc80NN': Value('float64'),\n",
      "'HRV_pNN50': Value('float64'),\n",
      "'HRV_pNN20': Value('float64'),\n",
      "'HRV_MinNN': Value('float64'),\n",
      "'HRV_MaxNN': Value('float64'),\n",
      "'HRV_HTI': Value('float64'),\n",
      "'HRV_TINN': Value('float64'),\n",
      "'HRV_ULF': Value('float64'),\n",
      "'HRV_VLF': Value('float64'),\n",
      "'HRV_LF': Value('float64'),\n",
      "'HRV_HF': Value('float64'),\n",
      "'HRV_VHF': Value('float64'),\n",
      "'HRV_TP': Value('float64'),\n",
      "'HRV_LFHF': Value('float64'),\n",
      "'HRV_LFn': Value('float64'),\n",
      "'HRV_HFn': Value('float64'),\n",
      "'HRV_LnHF': Value('float64'),\n",
      "'HRV_SD1': Value('float64'),\n",
      "'HRV_SD2': Value('float64'),\n",
      "'HRV_SD1SD2': Value('float64'),\n",
      "'HRV_S': Value('float64'),\n",
      "'HRV_CSI': Value('float64'),\n",
      "'HRV_CVI': Value('float64'),\n",
      "'HRV_CSI_Modified': Value('float64'),\n",
      "'HRV_PIP': Value('float64'),\n",
      "'HRV_IALS': Value('float64'),\n",
      "'HRV_PSS': Value('float64'),\n",
      "'HRV_PAS': Value('float64'),\n",
      "'HRV_GI': Value('float64'),\n",
      "'HRV_SI': Value('float64'),\n",
      "'HRV_AI': Value('float64'),\n",
      "'HRV_PI': Value('float64'),\n",
      "'HRV_C1d': Value('float64'),\n",
      "'HRV_C1a': Value('float64'),\n",
      "'HRV_SD1d': Value('float64'),\n",
      "'HRV_SD1a': Value('float64'),\n",
      "'HRV_C2d': Value('float64'),\n",
      "'HRV_C2a': Value('float64'),\n",
      "'HRV_SD2d': Value('float64'),\n",
      "'HRV_SD2a': Value('float64'),\n",
      "'HRV_Cd': Value('float64'),\n",
      "'HRV_Ca': Value('float64'),\n",
      "'HRV_SDNNd': Value('float64'),\n",
      "'HRV_SDNNa': Value('float64'),\n",
      "'HRV_DFA_alpha1': Value('float64'),\n",
      "'HRV_MFDFA_alpha1_Width': Value('float64'),\n",
      "'HRV_MFDFA_alpha1_Peak': Value('float64'),\n",
      "'HRV_MFDFA_alpha1_Mean': Value('float64'),\n",
      "'HRV_MFDFA_alpha1_Max': Value('float64'),\n",
      "'HRV_MFDFA_alpha1_Delta': Value('float64'),\n",
      "'HRV_MFDFA_alpha1_Asymmetry': Value('float64'),\n",
      "'HRV_MFDFA_alpha1_Fluctuation': Value('float64'),\n",
      "'HRV_MFDFA_alpha1_Increment': Value('float64'),\n",
      "'HRV_ApEn': Value('float64'),\n",
      "'HRV_SampEn': Value('float64'),\n",
      "'HRV_ShanEn': Value('float64'),\n",
      "'HRV_FuzzyEn': Value('float64'),\n",
      "'HRV_MSEn': Value('float64'),\n",
      "'HRV_CMSEn': Value('float64'),\n",
      "'HRV_RCMSEn': Value('float64'),\n",
      "'HRV_CD': Value('float64'),\n",
      "'HRV_HFD': Value('float64'),\n",
      "'HRV_KFD': Value('float64'),\n",
      "'HRV_LZC': Value('float64'),\n",
      "'label': Value('int32'),\n",
      "'mean_hr': Value('float64'),\n",
      "'std_hr': Value('float64'),\n",
      "'hrv_index': Value('float64'),\n",
      "'nn50': Value('int64'),\n",
      "'mean_hrv': Value('float64'),\n",
      "'std_hrv': Value('float64'),\n",
      "'rms_hrv': Value('float64'),\n",
      "'mean_fourier_frequencies': Value('float64'),\n",
      "'std_fourier_frequencies': Value('float64'),\n",
      "'sum_psd': Value('float64'),\n",
      "'ulf': Value('float64'),\n",
      "'lf': Value('float64'),\n",
      "'hf': Value('float64'),\n",
      "'uhf': Value('float64'),\n",
      "'lf_hf_ratio': Value('float64'),\n",
      "'total_power': Value('float64'),\n",
      "'relative_power_ulf': Value('float64'),\n",
      "'relative_power_lf': Value('float64'),\n",
      "'relative_power_hf': Value('float64'),\n",
      "'relative_power_vhf': Value('float64'),\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in zip(result.columns, result.dtypes):\n",
    "    print(f\"'{column}',\")\n",
    "\n",
    "for column, dtype in zip(result.columns, result.dtypes):\n",
    "    print(f\"'{column}': Value('{dtype}'),\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
