{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sia import Dataset\n",
    "\n",
    "# dataset = Dataset(\"Stress-in-Action\")\n",
    "\n",
    "# dataset.attach(\"./data/ecg_raw/*.edf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from torch.utils.data import Dataset as TorchDataset, IterableDataset\n",
    "from tabulate import tabulate\n",
    "from IPython.display import (\n",
    "    display, display_html, display_png, display_svg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarrow.parquet import ParquetDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarrow.parquet import ParquetDataset\n",
    "from sia.utils import get_file_paths, tqdm_joblib\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "target_labels = ['TA', 'SSST_Sing_countdown', 'Pasat', 'Raven', 'TA_repeat', 'Pasat_repeat']\n",
    "\n",
    "class Dataset(TorchDataset):#IterableDataset):\n",
    "    def __init__(self, name: str, window: int = 1000):\n",
    "        self.name = name\n",
    "        self.window = window\n",
    "        self.dataset = None\n",
    "\n",
    "    def attach(self, arg: str):\n",
    "        if isinstance(arg, str):\n",
    "            files = get_file_paths(arg)\n",
    "            self.dataset = ParquetDataset(files)\n",
    "        elif hasattr(arg, \"__len__\"):\n",
    "            files = arg\n",
    "            self.dataset = ParquetDataset(files)\n",
    "        else: \n",
    "            raise TypeError(\"The argument type is not supported\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum(p.count_rows() for p in self.dataset.fragments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = idx\n",
    "        print(\"Loop over pieces\")\n",
    "        for piece in ds.fragments:\n",
    "            print(\"PIECE ITERATION\")\n",
    "            if i - piece.count_rows() < 0:\n",
    "                print(\"FOUND\")\n",
    "                window = piece.take(list(range(idx, idx+self.window)), columns=['ECG_Clean', 'category'])\n",
    "                break\n",
    "            else:\n",
    "                print(\"NEXT\")\n",
    "                i -= piece.count_rows()\n",
    "        \n",
    "        if window is None:\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        print(\"PARSE DATA\")\n",
    "        signal = window['ECG_Clean'].to_numpy()\n",
    "        label = window['category'].to_numpy()\n",
    "        label[np.isin(label, target_labels)] = 1\n",
    "        label[~np.isin(label, target_labels)] = 0\n",
    "        \n",
    "        signal = torch.tensor(signal)\n",
    "        label = torch.tensor(label.astype(int))\n",
    "\n",
    "        print(\"FOUND\")\n",
    "        return signal, torch.tensor(1) if torch.mode(label, 0)[0] == 1 else torch.tensor(0)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        data = []\n",
    "\n",
    "        data.append([\"name\", self.name])\n",
    "\n",
    "        if len(self.dataset.fragments) > 0:\n",
    "            data.append([\"files\", len(self.dataset.fragments)])\n",
    "            \n",
    "            data.append([\"length\", [f.count_rows() for f in self.dataset.fragments]])\n",
    "\n",
    "        return tabulate(data, tablefmt=\"fancy_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sia.utils import get_file_paths, tqdm_joblib\n",
    "\n",
    "# pd.options.mode.chained_assignment = None\n",
    "# target_labels = ['TA', 'SSST_Sing_countdown', 'Pasat', 'Raven', 'TA_repeat', 'Pasat_repeat']\n",
    "\n",
    "# class Dataset(TorchDataset):#IterableDataset):\n",
    "#     def __init__(self, name: str, window: int = 1000):\n",
    "#         self.name = name\n",
    "#         self.window = window\n",
    "\n",
    "#         self.files = []\n",
    "\n",
    "#     def attach(self, arg: str):\n",
    "#         def count_lines(file: str) -> int:\n",
    "#             n = len(pd.read_feather(file))\n",
    "#             return (file, n)\n",
    "\n",
    "#         if isinstance(arg, str):\n",
    "#             files = get_file_paths(arg)\n",
    "#             self.files = Parallel(n_jobs=4)(delayed(count_lines)(f) for f in files)\n",
    "#         elif hasattr(arg, \"__len__\"):\n",
    "#             files = arg\n",
    "#             self.files = Parallel(n_jobs=4)(delayed(count_lines)(f) for f in files)\n",
    "#         else: \n",
    "#             raise TypeError(\"The argument type is not supported\")\n",
    "        \n",
    "#         return self\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return sum([f[1] for f in self.files]) - self.window\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         for f in self.files:\n",
    "#             df = pd.read_csv(f[0])\n",
    "#             for window in list(df.rolling(self.window)):\n",
    "#                 signal = window['ECG_Clean']\n",
    "#                 label = window['category']\n",
    "#                 label[label.isin(target_labels)] = 1\n",
    "#                 label[~label.isin(target_labels)] = 0\n",
    "                \n",
    "#                 signal = torch.tensor(signal)\n",
    "#                 label = torch.tensor(label)\n",
    "\n",
    "#                 yield signal, label\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         i = idx\n",
    "#         for f in self.files:\n",
    "#             if i - f[1] < 0:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 i -= f[1]\n",
    "\n",
    "#         row = pd.read_feather(f[0], columns=['ECG_Clean', 'category'])\n",
    "#         row = row.iloc[i:i+self.window]\n",
    "        \n",
    "#         signal = row['ECG_Clean']\n",
    "#         label = row['category']\n",
    "#         label[label.isin(target_labels)] = 1\n",
    "#         label[~label.isin(target_labels)] = 0\n",
    "\n",
    "#         label = label.to_numpy(dtype=int)\n",
    "        \n",
    "#         signal = torch.tensor(signal.to_numpy())\n",
    "#         label = torch.tensor(label)\n",
    "\n",
    "#         return signal, torch.tensor(1) if torch.mode(label, 0)[0] == 1 else torch.tensor(0)\n",
    "        \n",
    "#     def __repr__(self):\n",
    "#         data = []\n",
    "\n",
    "#         data.append([\"name\", self.name])\n",
    "\n",
    "#         if len(self.files) > 0:\n",
    "#             data.append([\"files\", len(self.files)])\n",
    "#             data.append([\"file paths\", [f[0] for f in self.files]])\n",
    "#             data.append([\"length\", [f[1] for f in self.files]])\n",
    "\n",
    "#         return tabulate(data, tablefmt=\"fancy_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = glob.glob(\"./data/parquet/*.parquet\")\n",
    "train_participants, test_participants = train_test_split(participants, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "╒════════╤═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╕\n",
       "│ name   │ Stress-in-Action                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              │\n",
       "├────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ files  │ 101                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           │\n",
       "├────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ length │ [7847000, 6959000, 8624000, 7656000, 7805000, 7324000, 7023000, 9173000, 7873000, 7371000, 8123000, 7633000, 8050000, 7238000, 7662000, 7289000, 7192000, 7112000, 7828000, 7726000, 7823000, 7050000, 7861000, 8568000, 8212000, 7717000, 7337000, 7249000, 8142000, 7641000, 7880000, 7982000, 7013000, 6830000, 7381000, 8129000, 7902000, 7063000, 8849000, 7955000, 8211000, 9622000, 7678000, 7737000, 7278000, 8207000, 7297000, 7769000, 7583000, 6906000, 7482000, 7296000, 7413000, 6941000, 7237000, 8439000, 7588000, 7347000, 7312000, 7059000, 9684000, 7275000, 8164000, 7652000, 7479000, 7232000, 7012000, 8035000, 8143000, 8174000, 7075000, 6913000, 8344000, 7203000, 8692000, 7405000, 8185000, 7185000, 7261000, 7462000, 7451000, 7589000, 7419000, 7376000, 8139000, 8309000, 8370000, 7744000, 7871000, 9975000, 7552000, 8540000, 7176000, 7241000, 6866000, 7729000, 8025000, 7875000, 7259000, 8718000, 7325000] │\n",
       "╘════════╧═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╛"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = Dataset(\"Stress-in-Action\")\n",
    "ds_train.attach(train_participants)\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "╒════════╤═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╕\n",
       "│ name   │ Stress-in-Action                                                                                                                                                                                                                            │\n",
       "├────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ files  │ 26                                                                                                                                                                                                                                          │\n",
       "├────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ length │ [7726000, 7870000, 8089000, 8530000, 7835000, 7695000, 7243000, 7542000, 7106000, 7350000, 10272000, 7762000, 7346000, 6100000, 7997000, 7772000, 9241000, 7397000, 7206000, 7842000, 6658000, 7087000, 7326000, 7112000, 7971000, 7985000] │\n",
       "╘════════╧═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╛"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test = Dataset(\"Stress-in-Action\")\n",
    "ds_test.attach(test_participants)\n",
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(ds_train, batch_size=32, shuffle=False, drop_last=True, num_workers=4, pin_memory=True)\n",
    "test_dataloader = DataLoader(ds_test, batch_size=32, shuffle=False, drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:llyr4xhi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-night-6</strong> at: <a href='https://wandb.ai/alex-antonides/stress-in-action/runs/llyr4xhi' target=\"_blank\">https://wandb.ai/alex-antonides/stress-in-action/runs/llyr4xhi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240208_130438-llyr4xhi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:llyr4xhi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\university\\thesis\\wandb\\run-20240208_130507-zb6ojjse</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alex-antonides/stress-in-action/runs/zb6ojjse' target=\"_blank\">colorful-frost-7</a></strong> to <a href='https://wandb.ai/alex-antonides/stress-in-action' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alex-antonides/stress-in-action' target=\"_blank\">https://wandb.ai/alex-antonides/stress-in-action</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alex-antonides/stress-in-action/runs/zb6ojjse' target=\"_blank\">https://wandb.ai/alex-antonides/stress-in-action/runs/zb6ojjse</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/alex-antonides/stress-in-action/runs/zb6ojjse?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x11a17b1da90>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"stress-in-action\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"SiA\",\n",
    "        \"epochs\": 11,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
    "from torch import nn\n",
    "\n",
    "class Test(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(1000, 10).double(),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(10, 1).double(),\n",
    "            nn.Softmax(1),\n",
    "        )\n",
    "\n",
    "        self.layers.cuda(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.layers(x)\n",
    "        return embedding\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        wandb.log({\"loss\": loss})\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        wandb.log({\"val_loss\": loss})\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | layers | Sequential | 10.0 K\n",
      "--------------------------------------\n",
      "10.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.0 K    Total params\n",
      "0.040     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 43/1514804 [13:37<7994:40:40,  0.05it/s, v_num=31]"
     ]
    }
   ],
   "source": [
    "model = Test()\n",
    "trainer = L.Trainer(max_epochs=11, accelerator=\"gpu\", devices=1)\n",
    "trainer.fit(model, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.0</td></tr><tr><td>val_loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">serene-silence-2</strong> at: <a href='https://wandb.ai/alex-antonides/stress-in-action/runs/6w7jk2n5' target=\"_blank\">https://wandb.ai/alex-antonides/stress-in-action/runs/6w7jk2n5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240207_142340-6w7jk2n5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
