{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sia import Pipeline\n",
    "from sia.io import Metadata, read_edf, read_csv, write_csv\n",
    "from sia.preprocessors import neurokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finalizing... ./data/ecg_raw\\30235_LAB_Conditions_ECG.edf: : 127it [3:00:53, 85.46s/it]          \n"
     ]
    }
   ],
   "source": [
    "Pipeline() \\\n",
    "    .data(\n",
    "        read_edf(\n",
    "            './data/ecg_raw/*.edf', \n",
    "            Metadata('./data/ecg_raw/TimeStamps_Merged.txt').on_regex(r'[0-9]{5}')\n",
    "        )\n",
    "    ) \\\n",
    "    .preprocess(neurokit()) \\\n",
    "    .to(write_csv('./data/test/[0-9]{5}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(data: np.ndarray):\n",
    "    \"\"\"\n",
    "        From (timestamp, category, ecg) to (ecg, category) \n",
    "    \"\"\"\n",
    "    return data[:, [2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = ['TA', 'SSST_Sing_countdown', 'Pasat', 'Raven', 'TA_repeat', 'Pasat_repeat']\n",
    "\n",
    "def encode_category(data: np.ndarray):\n",
    "    \"\"\"\n",
    "        From (ecg, category) to (ecg, bool)\n",
    "    \"\"\"\n",
    "    data[:, 1][~np.isin(data[:, 1], target_labels)] = 0\n",
    "    data[:, 1][np.isin(data[:, 1], target_labels)] = 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finalizing... ./data/test\\30235.csv: : 127it [26:03, 12.31s/it]          \n"
     ]
    }
   ],
   "source": [
    "Pipeline() \\\n",
    "    .data(read_csv('./data/test/*.csv')) \\\n",
    "    .reduce(reduce) \\\n",
    "    .postprocess(encode_category) \\\n",
    "    .to(write_csv('./data/test_2/[0-9]{5}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset as HFDataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "\n",
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data: HFDataset, window: int = 1000):\n",
    "        self.data = data\n",
    "        self.window = window\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx + self.window > len(self.data):\n",
    "            raise StopIteration\n",
    "\n",
    "        window = self.data[idx: idx + self.window]\n",
    "\n",
    "        x = window['signal']\n",
    "        y = torch.tensor(1, device='cuda') if torch.mode(window['label'], 0)[0] == 1 else torch.tensor(0, device='cuda')\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "participants = glob(\"./data/smoll/*.csv\")\n",
    "train_participants, test_participants = train_test_split(participants, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('csv', data_files={\n",
    "    'train': train_participants[:1],\n",
    "    'test': test_participants[:1]\n",
    "}, column_names=['signal', 'label'], num_proc=8)\n",
    "\n",
    "data = data.with_format('torch', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data['train'])\n",
    "test_dataset = Dataset(data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1024)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.6 s ± 105 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit for x in train_dataloader: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.6 s ± 97.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit for x in train_dataloader: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malex-antonides\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\university\\thesis\\wandb\\run-20240215_023529-v54a27e2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alex-antonides/stress-in-action/runs/v54a27e2' target=\"_blank\">velvety-balloon-41</a></strong> to <a href='https://wandb.ai/alex-antonides/stress-in-action' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alex-antonides/stress-in-action' target=\"_blank\">https://wandb.ai/alex-antonides/stress-in-action</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alex-antonides/stress-in-action/runs/v54a27e2' target=\"_blank\">https://wandb.ai/alex-antonides/stress-in-action/runs/v54a27e2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/alex-antonides/stress-in-action/runs/v54a27e2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x23341f181d0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"stress-in-action\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"SiA\",\n",
    "        \"epochs\": 11,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | layers | Sequential | 10.0 K\n",
      "--------------------------------------\n",
      "10.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.0 K    Total params\n",
      "0.040     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 184/21619862 [00:11<372:29:50, 16.12it/s, v_num=87]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
    "from torch import nn\n",
    "\n",
    "class Test(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(1000, 10),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Softmax(-1),\n",
    "        )\n",
    "\n",
    "        self.layers.cuda(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.layers(x)\n",
    "        return embedding\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        wandb.log({\"loss\": loss})\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        wandb.log({\"val_loss\": loss})\n",
    "        return loss\n",
    "\n",
    "model = Test()\n",
    "model.cuda()\n",
    "trainer = L.Trainer(max_epochs=11, accelerator=\"gpu\", devices=\"auto\", strategy=\"auto\", profiler=\"simple\")\n",
    "trainer.fit(model, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yearning-infatuation-40</strong> at: <a href='https://wandb.ai/alex-antonides/stress-in-action/runs/bjvohuyc' target=\"_blank\">https://wandb.ai/alex-antonides/stress-in-action/runs/bjvohuyc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240214_210616-bjvohuyc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
