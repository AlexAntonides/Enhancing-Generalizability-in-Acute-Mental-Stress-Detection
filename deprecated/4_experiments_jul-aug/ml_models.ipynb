{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, balanced_accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data/ecg_features_60s_clean_twa_rqa_60s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels =  [\n",
    "    \"hrv_mean\",\n",
    "    \"hrv_min\",\n",
    "    \"hrv_max\",\n",
    "    \"hrv_std\",\n",
    "    \"hrv_rms\",\n",
    "    \"hr_mean\",\n",
    "    \"hr_min\",\n",
    "    \"hr_max\",\n",
    "    \"rr_mean\",\n",
    "    \"rr_min\",\n",
    "    \"rr_max\",\n",
    "    \"rr_std\",\n",
    "    \"nn50\",\n",
    "    \"pnn50\",\n",
    "    \"rmssd\",\n",
    "    \"lf\",\n",
    "    \"hf\",\n",
    "    \"vhf\",\n",
    "    \"uhf\",\n",
    "    \"tp\",\n",
    "    \"lp_hf\",\n",
    "    \"lp_vhf\",\n",
    "    \"lp_uhf\",\n",
    "    \"hf_normalized\",\n",
    "    \"w\",\n",
    "    \"wmax\",\n",
    "    \"wen\",\n",
    "    \"MeanNN\",\n",
    "    \"SDNN\",\n",
    "    \"SDANN1\",\n",
    "    \"SDNNI1\",\n",
    "    \"SDANN2\",\n",
    "    \"SDNNI2\",\n",
    "    \"SDANN5\",\n",
    "    \"SDNNI5\",\n",
    "    \"RMSSD\",\n",
    "    \"SDSD\",\n",
    "    \"CVNN\",\n",
    "    \"CVSD\",\n",
    "    \"MedianNN\",\n",
    "    \"MadNN\",\n",
    "    \"MCVNN\",\n",
    "    \"IQRNN\",\n",
    "    \"SDRMSSD\",\n",
    "    \"Prc20NN\",\n",
    "    \"Prc80NN\",\n",
    "    \"pNN50\",\n",
    "    \"pNN20\",\n",
    "    \"MinNN\",\n",
    "    \"MaxNN\",\n",
    "    \"HTI\",\n",
    "    \"TINN\",\n",
    "    \"twa\",\n",
    "]\n",
    "y_label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [Path(path).stem for path in glob(f'{base_path}/*.csv')]\n",
    "train_participants, test_participants = train_test_split(participants, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(baseline = 0, mental_stress = -1, high_physical_activity = -1, moderate_physical_activity = -1, low_physical_activity = -1):\n",
    "    def inner(labels):\n",
    "        baseline_list = ['Sitting', 'Recov1', 'Recov2', 'Recov3', 'Recov4', 'Recov5', 'Recov6']\n",
    "        mental_stress_list = ['TA', 'SSST_Sing_countdown', 'Pasat', 'Raven', 'TA_repeat', 'Pasat_repeat']\n",
    "        high_physical_stress_list = ['Treadmill1', 'Treadmill2', 'Treadmill3', 'Treadmill4', 'Walking_fast_pace', 'Cycling', 'stairs_up_and_down']\n",
    "        moderate_physical_stress_list = ['Walking_own_pace', 'Dishes', 'Vacuum']\n",
    "        low_physical_stress_list = ['Standing', 'Lying_supine', 'Recov_standing']\n",
    "        \n",
    "        def encode_multiclass(label):\n",
    "            if label in baseline_list:\n",
    "                return baseline\n",
    "            elif label in mental_stress_list:\n",
    "                return mental_stress\n",
    "            elif label in high_physical_stress_list:\n",
    "                return high_physical_activity\n",
    "            elif label in moderate_physical_stress_list:\n",
    "                return moderate_physical_activity\n",
    "            elif label in low_physical_stress_list:\n",
    "                return low_physical_activity\n",
    "            else:\n",
    "                return -1\n",
    "            \n",
    "        return {\n",
    "            'label': [encode_multiclass(label) for label in labels],\n",
    "        }\n",
    "    return inner\n",
    "\n",
    "def clean(dataset, mapping={}):\n",
    "    dataset = dataset.map(\n",
    "        encode(**mapping), \n",
    "        batched=True, \n",
    "        batch_size=2048, \n",
    "        input_columns=['label'],\n",
    "        num_proc=4\n",
    "    )\n",
    "    return dataset.filter(\n",
    "        lambda label: label != -1,\n",
    "        input_columns=['label'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Enum):\n",
    "    DecisionTree = 1\n",
    "    RandomForest = 2\n",
    "    AdaBoost = 3\n",
    "    LinearDescriminantAnalysis = 4\n",
    "    KNearestNeighbors = 5\n",
    "    LogisticRegression = 6\n",
    "    XGBoost = 7\n",
    "    QuadraticDiscriminantAnalysis = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: Model, train_indices, val_indices, params= {}, mapping = {}):\n",
    "    dataset = datasets.load_dataset(\n",
    "        f'{base_path}', \n",
    "        train_participants=[train_participants[i] for i in train_indices],\n",
    "        val_participants=[train_participants[i] for i in val_indices],\n",
    "        test_participants=test_participants,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    dataset = clean(dataset, mapping=mapping)\n",
    "    train = dataset['fit'].to_pandas().replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "    X_train, y_train = train[X_labels], train[y_label]\n",
    "    del train\n",
    "\n",
    "    if model == Model.DecisionTree:\n",
    "        cls = DecisionTreeClassifier(criterion='entropy', min_samples_split=20, **params, random_state=42)\n",
    "    elif model == Model.RandomForest:\n",
    "        cls = RandomForestClassifier(**params, random_state=42, bootstrap=False)\n",
    "    elif model == Model.AdaBoost:\n",
    "        cls = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy', min_samples_split=20), n_estimators=100, **params)\n",
    "    elif model == Model.LinearDescriminantAnalysis:\n",
    "        cls = LinearDiscriminantAnalysis(**params)\n",
    "    elif model == Model.KNearestNeighbors:\n",
    "        cls = KNeighborsClassifier(n_neighbors=9, **params)\n",
    "    elif model == Model.LogisticRegression:\n",
    "        cls = LogisticRegression(**params)\n",
    "    elif model == Model.XGBoost:\n",
    "        cls = XGBClassifier(**params)\n",
    "    elif model == Model.QuadraticDiscriminantAnalysis:\n",
    "        cls = QuadraticDiscriminantAnalysis(**params)\n",
    "\n",
    "    cls.fit(X_train, y_train)\n",
    "\n",
    "    del X_train\n",
    "\n",
    "    val = dataset['validate'].to_pandas().replace([np.inf, -np.inf, np.nan], 0)\n",
    "    X_val, y_val = val[X_labels], val[y_label]\n",
    "    del val\n",
    "\n",
    "    test = dataset['test'].to_pandas().replace([np.inf, -np.inf, np.nan], 0)\n",
    "    X_test, y_test = test[X_labels], test[y_label]\n",
    "    del test\n",
    "\n",
    "    data = {\n",
    "        'val_accuracy': sklearn.metrics.accuracy_score(y_val, cls.predict(X_val)),\n",
    "        'val_balanced_accuracy': sklearn.metrics.balanced_accuracy_score(y_val, cls.predict(X_val)),\n",
    "        'test_accuracy': sklearn.metrics.accuracy_score(y_test, cls.predict(X_test)),\n",
    "        'test_balanced_accuracy': sklearn.metrics.balanced_accuracy_score(y_test, cls.predict(X_test)),\n",
    "    }\n",
    "\n",
    "    if len(y_train.unique()) == 2:\n",
    "        ## binary\n",
    "        data['val_f1'] = sklearn.metrics.f1_score(y_val, cls.predict(X_val))\n",
    "        data['test_f1'] = sklearn.metrics.f1_score(y_test, cls.predict(X_test))\n",
    "    else: \n",
    "        # multiclass\n",
    "        data['val_f1'] = sklearn.metrics.f1_score(y_val, cls.predict(X_val), average='micro')\n",
    "        data['test_f1'] = sklearn.metrics.f1_score(y_test, cls.predict(X_test), average='micro')\n",
    "\n",
    "    del y_train, X_val, y_val\n",
    "    del X_test, y_test\n",
    "\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline & Mental Stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attempt(model: Model):\n",
    "    table = PrettyTable()\n",
    "    table.title = f'{model.name}'\n",
    "    table.field_names = [\n",
    "        '',\n",
    "        'Validation F1', \n",
    "        'Test F1', \n",
    "        'Validation Accuracy', \n",
    "        'Test Accuracy', \n",
    "        'Validation Balanced Accuracy', \n",
    "        'Test Balanced Accuracy'\n",
    "    ]\n",
    "\n",
    "    with tqdm(total=3) as pbar:\n",
    "        for mapping in [ { \"mental_stress\": 1 }, { \"high_physical_activity\": 1 }, { \"baseline\": -1, \"mental_stress\": 0, \"high_physical_activity\": 1 } ]:\n",
    "            pbar.set_description(f'{model.name} - {mapping}')\n",
    "            scores = Parallel(n_jobs=3)(delayed(train)(\n",
    "                model,\n",
    "                train_indices, \n",
    "                val_indices, \n",
    "                mapping=mapping\n",
    "            ) for train_indices, val_indices in KFold(n_splits=5, shuffle=True, random_state=42).split(train_participants)) \n",
    "            df = pd.DataFrame(scores)\n",
    "\n",
    "            titles = []\n",
    "            if (\"baseline\" not in mapping) or (mapping[\"baseline\"] != -1):\n",
    "                titles.append(\"Baseline\")\n",
    "            if \"mental_stress\" in mapping and mapping[\"mental_stress\"] >= 0:\n",
    "                titles.append(\"Mental Stress\")\n",
    "            if \"high_physical_activity\" in mapping and mapping[\"high_physical_activity\"] >= 0:\n",
    "                titles.append(\"High Physical Activity\")\n",
    "\n",
    "            table.add_row([\n",
    "                f\"{' & '.join(titles)}\",\n",
    "                f\"{round(df['val_f1'].mean() * 100, 2)}% ± {round(df['val_f1'].std() * 100, 2)}%\", \n",
    "                f\"{round(df['test_f1'].mean() * 100, 2)}% ± {round(df['test_f1'].std() * 100, 2)}%\", \n",
    "                f\"{round(df['val_accuracy'].mean() * 100, 2)}% ± {round(df['val_accuracy'].std() * 100, 2)}%\", \n",
    "                f\"{round(df['test_accuracy'].mean() * 100, 2)}% ± {round(df['test_accuracy'].std() * 100, 2)}%\", \n",
    "                f\"{round(df['val_balanced_accuracy'].mean() * 100, 2)}% ± {round(df['val_balanced_accuracy'].std() * 100, 2)}%\", \n",
    "                f\"{round(df['test_balanced_accuracy'].mean() * 100, 2)}% ± {round(df['test_balanced_accuracy'].std() * 100, 2)}%\"\n",
    "            ])\n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                               DecisionTree                                                                              |\n",
      "+----------------------------------------+----------------+----------------+---------------------+----------------+------------------------------+------------------------+\n",
      "|                                        | Validation F1  |    Test F1     | Validation Accuracy | Test Accuracy  | Validation Balanced Accuracy | Test Balanced Accuracy |\n",
      "+----------------------------------------+----------------+----------------+---------------------+----------------+------------------------------+------------------------+\n",
      "|        Baseline & Mental Stress        | 58.51% ± 0.41% | 58.49% ± 0.24% |    55.42% ± 0.62%   | 55.51% ± 0.25% |        55.17% ± 0.77%        |     55.29% ± 0.27%     |\n",
      "|   Baseline & High Physical Activity    | 84.85% ± 1.13% | 83.91% ± 0.44% |    85.92% ± 1.11%   | 84.71% ± 0.33% |        85.87% ± 1.03%        |     84.94% ± 0.38%     |\n",
      "| Mental Stress & High Physical Activity | 81.04% ± 1.13% | 78.43% ± 0.49% |    83.59% ± 1.42%   | 80.46% ± 0.51% |        83.37% ± 1.1%         |     80.69% ± 0.47%     |\n",
      "+----------------------------------------+----------------+----------------+---------------------+----------------+------------------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "attempt(Model.DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m Model\u001b[38;5;241m.\u001b[39mRandomForest:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mattempt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 15\u001b[0m, in \u001b[0;36mattempt\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      4\u001b[0m table\u001b[38;5;241m.\u001b[39mfield_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation F1\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Balanced Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mapping \u001b[38;5;129;01min\u001b[39;00m [ { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmental_stress\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m }, { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh_physical_activity\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m }, { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmental_stress\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh_physical_activity\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m } ]:\n\u001b[1;32m---> 15\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_participants\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     21\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scores)\n\u001b[0;32m     23\u001b[0m     titles \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model in Model:\n",
    "    if model == Model.DecisionTree:\n",
    "        continue\n",
    "    elif model == Model.RandomForest:\n",
    "        continue\n",
    "    attempt(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
