{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, balanced_accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data/ecg_features_60s_clean_twa_rqa_60s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels =  [\n",
    "    'hrv_mean',\n",
    "    'hrv_min',\n",
    "    'hrv_max',\n",
    "    'hrv_std',\n",
    "    'hrv_rms',\n",
    "    'TINN',\n",
    "    'hr_mean',\n",
    "    'hr_min',\n",
    "    'hr_max',\n",
    "    'hr_std',\n",
    "    'rr_mean',\n",
    "    'rr_min',\n",
    "    'rr_max',\n",
    "    'rr_std',\n",
    "    'nn50',\n",
    "    'pnn50',\n",
    "    'rmssd',\n",
    "    'twa',\n",
    "\n",
    "    # new\n",
    "    'vhf_entropy',  # 0.28\n",
    "    'lp_vhf_entropy', # 0.28\n",
    "    'lp_vhf_max',   # 0.25\n",
    "    'vhf_max',   # 0.25\n",
    "    'lp_vhf_mean',   # 0.24\n",
    "    'lp_vhf_std',   # 0.24\n",
    "    'lp_vhf_energy', # 0.22\n",
    "    'lp_vhf_power', # 0.22\n",
    "    'lp_vhf_median',      # 0.21\n",
    "    'vhf_std',      # 0.21\n",
    "    'vhf_power',    # 0.21\n",
    "    'vhf_mean',    # 0.21\n",
    "    'tp_entropy',   # 0.21\n",
    "    'vhf_median', # 0.19\n",
    "    'lp_vhf_covariance', # 0.17\n",
    "    'lp_lf_min', # 0.17\n",
    "    'w',            # 0.17\n",
    "    'PSS',          # 0.17\n",
    "    'wmax',         # 0.16\n",
    "    'hr_min',       # 0.16\n",
    "    'lp_uhf_entropy', # 0.16\n",
    "    'wen',          # 0.15\n",
    "    'hr_mean',      # 0.15\n",
    "    'PIP',          # 0.15\n",
    "    'hf_entropy',   # 0.15\n",
    "    'uhf_entropy',  # 0.14\n",
    "    'IALS',         # 0.14\n",
    "    'FuzzyEn',      # 0.14\n",
    "    'SampEn',       # 0.13\n",
    "]\n",
    "y_label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [Path(path).stem for path in glob(f'{base_path}/*.csv')]\n",
    "train_participants, test_participants = train_test_split(participants, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(baseline = 0, mental_stress = -1, high_physical_activity = -1, moderate_physical_activity = -1, low_physical_activity = -1):\n",
    "    def inner(labels):\n",
    "        baseline_list = ['Sitting', 'Recov1', 'Recov2', 'Recov3', 'Recov4', 'Recov5', 'Recov6']\n",
    "        mental_stress_list = ['TA', 'SSST_Sing_countdown', 'Pasat', 'Raven', 'TA_repeat', 'Pasat_repeat']\n",
    "        high_physical_stress_list = ['Treadmill1', 'Treadmill2', 'Treadmill3', 'Treadmill4', 'Walking_fast_pace', 'Cycling', 'stairs_up_and_down']\n",
    "        moderate_physical_stress_list = ['Walking_own_pace', 'Dishes', 'Vacuum']\n",
    "        low_physical_stress_list = ['Standing', 'Lying_supine', 'Recov_standing']\n",
    "        \n",
    "        def encode_multiclass(label):\n",
    "            if label in baseline_list:\n",
    "                return baseline\n",
    "            elif label in mental_stress_list:\n",
    "                return mental_stress\n",
    "            elif label in high_physical_stress_list:\n",
    "                return high_physical_activity\n",
    "            elif label in moderate_physical_stress_list:\n",
    "                return moderate_physical_activity\n",
    "            elif label in low_physical_stress_list:\n",
    "                return low_physical_activity\n",
    "            else:\n",
    "                return -1\n",
    "            \n",
    "        return {\n",
    "            'label': [encode_multiclass(label) for label in labels],\n",
    "        }\n",
    "    return inner\n",
    "\n",
    "def clean(dataset, mapping={}):\n",
    "    dataset = dataset.map(\n",
    "        encode(**mapping), \n",
    "        batched=True, \n",
    "        batch_size=2048, \n",
    "        input_columns=['label'],\n",
    "        num_proc=4\n",
    "    )\n",
    "    return dataset.filter(\n",
    "        lambda label: label != -1,\n",
    "        input_columns=['label'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Enum):\n",
    "    RandomForest = 2\n",
    "    DecisionTree = 1\n",
    "    AdaBoost = 3\n",
    "    LinearDiscriminantAnalysis = 4\n",
    "    KNearestNeighbors = 5\n",
    "    LogisticRegression = 6\n",
    "    XGBoost = 7\n",
    "    QuadraticDiscriminantAnalysis = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: int, train_indices, val_indices, params= {}, mapping = {}):\n",
    "    dataset = datasets.load_dataset(\n",
    "        f'{base_path}', \n",
    "        train_participants=[train_participants[i] for i in train_indices],\n",
    "        val_participants=[train_participants[i] for i in val_indices],\n",
    "        test_participants=test_participants,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    dataset = clean(dataset, mapping=mapping)\n",
    "    train = dataset['fit'].to_pandas().replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "    X_train, y_train = train[X_labels], train[y_label]\n",
    "    del train\n",
    "\n",
    "    if model == 1:\n",
    "        cls = DecisionTreeClassifier(criterion='entropy', min_samples_split=20, **params, random_state=42)\n",
    "    elif model == 2:\n",
    "        cls = RandomForestClassifier(**params, random_state=42, bootstrap=False)\n",
    "    elif model == 3:\n",
    "        cls = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy', min_samples_split=20), n_estimators=100, **params)\n",
    "    elif model == 4:\n",
    "        cls = LinearDiscriminantAnalysis(**params)\n",
    "    elif model == 5:\n",
    "        cls = KNeighborsClassifier(n_neighbors=9, **params)\n",
    "    elif model == 6:\n",
    "        cls = LogisticRegression(**params)\n",
    "    elif model == 7:\n",
    "        cls = XGBClassifier(**params)\n",
    "    elif model == 8:\n",
    "        cls = QuadraticDiscriminantAnalysis(**params)\n",
    "    else: \n",
    "        raise ValueError('Invalid model')\n",
    "\n",
    "    cls.fit(X_train, y_train)\n",
    "\n",
    "    del X_train\n",
    "\n",
    "    val = dataset['validate'].to_pandas().replace([np.inf, -np.inf, np.nan], 0)\n",
    "    X_val, y_val = val[X_labels], val[y_label]\n",
    "    del val\n",
    "\n",
    "    test = dataset['test'].to_pandas().replace([np.inf, -np.inf, np.nan], 0)\n",
    "    X_test, y_test = test[X_labels], test[y_label]\n",
    "    del test\n",
    "\n",
    "    data = {\n",
    "        'val_accuracy': sklearn.metrics.accuracy_score(y_val, cls.predict(X_val)),\n",
    "        'val_balanced_accuracy': sklearn.metrics.balanced_accuracy_score(y_val, cls.predict(X_val)),\n",
    "        'test_accuracy': sklearn.metrics.accuracy_score(y_test, cls.predict(X_test)),\n",
    "        'test_balanced_accuracy': sklearn.metrics.balanced_accuracy_score(y_test, cls.predict(X_test)),\n",
    "    }\n",
    "\n",
    "    if len(y_train.unique()) == 2:\n",
    "        ## binary\n",
    "        data['val_f1'] = sklearn.metrics.f1_score(y_val, cls.predict(X_val))\n",
    "        data['test_f1'] = sklearn.metrics.f1_score(y_test, cls.predict(X_test))\n",
    "    else: \n",
    "        # multiclass\n",
    "        data['val_f1'] = sklearn.metrics.f1_score(y_val, cls.predict(X_val), average='micro')\n",
    "        data['test_f1'] = sklearn.metrics.f1_score(y_test, cls.predict(X_test), average='micro')\n",
    "\n",
    "    del y_train, X_val, y_val\n",
    "    del X_test, y_test\n",
    "\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline & Mental Stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attempt(model: Model):\n",
    "    table = PrettyTable()\n",
    "    table.title = f'{model.name}'\n",
    "    table.field_names = [\n",
    "        '',\n",
    "        'Validation F1', \n",
    "        'Test F1', \n",
    "        'Validation Accuracy', \n",
    "        'Test Accuracy', \n",
    "        'Validation Balanced Accuracy', \n",
    "        'Test Balanced Accuracy'\n",
    "    ]\n",
    "\n",
    "    value = int(model.value)\n",
    "    mappings = [ { \"mental_stress\": 1 } ] #, { \"high_physical_activity\": 1 }, { \"baseline\": -1, \"mental_stress\": 0, \"high_physical_activity\": 1 } ]\n",
    "    with tqdm(total=len(mappings)) as pbar:\n",
    "        for mapping in mappings:\n",
    "            pbar.set_description(f'{model.name} - {mapping}')\n",
    "            scores = Parallel(n_jobs=1)(delayed(train)(\n",
    "                value,\n",
    "                train_indices, \n",
    "                val_indices, \n",
    "                mapping=mapping\n",
    "            ) for train_indices, val_indices in KFold(n_splits=2, shuffle=True, random_state=42).split(train_participants)) \n",
    "            df = pd.DataFrame(scores)\n",
    "\n",
    "            titles = []\n",
    "            if (\"baseline\" not in mapping) or (mapping[\"baseline\"] != -1):\n",
    "                titles.append(\"Baseline\")\n",
    "            if \"mental_stress\" in mapping and mapping[\"mental_stress\"] >= 0:\n",
    "                titles.append(\"Mental Stress\")\n",
    "            if \"high_physical_activity\" in mapping and mapping[\"high_physical_activity\"] >= 0:\n",
    "                titles.append(\"High Physical Activity\")\n",
    "\n",
    "            row = [\n",
    "                f\"{' & '.join(titles)}\",\n",
    "                f\"{round(df['val_f1'].mean() * 100, 2)}% ± {round(df['val_f1'].std() * 100, 2)}%\", \n",
    "                f\"{round(df['test_f1'].mean() * 100, 2)}% ± {round(df['test_f1'].std() * 100, 2)}%\", \n",
    "                f\"{round(df['val_accuracy'].mean() * 100, 2)}% ± {round(df['val_accuracy'].std() * 100, 2)}%\", \n",
    "                f\"{round(df['test_accuracy'].mean() * 100, 2)}% ± {round(df['test_accuracy'].std() * 100, 2)}%\", \n",
    "                f\"{round(df['val_balanced_accuracy'].mean() * 100, 2)}% ± {round(df['val_balanced_accuracy'].std() * 100, 2)}%\", \n",
    "                f\"{round(df['test_balanced_accuracy'].mean() * 100, 2)}% ± {round(df['test_balanced_accuracy'].std() * 100, 2)}%\"\n",
    "            ]\n",
    "            print(\"Intermediate results: \", row)\n",
    "            table.add_row(row)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest - {'mental_stress': 1}: 100%|██████████| 1/1 [3:45:00<00:00, 13500.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate results:  ['Baseline & Mental Stress', '62.32% ± 1.56%', '62.74% ± 0.5%', '58.92% ± 0.53%', '58.73% ± 0.59%', '58.56% ± 0.3%', '58.34% ± 0.74%']\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                       RandomForest                                                                       |\n",
      "+--------------------------+----------------+---------------+---------------------+----------------+------------------------------+------------------------+\n",
      "|                          | Validation F1  |    Test F1    | Validation Accuracy | Test Accuracy  | Validation Balanced Accuracy | Test Balanced Accuracy |\n",
      "+--------------------------+----------------+---------------+---------------------+----------------+------------------------------+------------------------+\n",
      "| Baseline & Mental Stress | 62.32% ± 1.56% | 62.74% ± 0.5% |    58.92% ± 0.53%   | 58.73% ± 0.59% |        58.56% ± 0.3%         |     58.34% ± 0.74%     |\n",
      "+--------------------------+----------------+---------------+---------------------+----------------+------------------------------+------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DecisionTree - {'mental_stress': 1}: 100%|██████████| 1/1 [6:55:51<00:00, 24951.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate results:  ['Baseline & Mental Stress', '58.59% ± 0.82%', '58.13% ± 0.47%', '55.63% ± 0.06%', '55.32% ± 0.12%', '55.4% ± 0.07%', '55.12% ± 0.19%']\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                        DecisionTree                                                                       |\n",
      "+--------------------------+----------------+----------------+---------------------+----------------+------------------------------+------------------------+\n",
      "|                          | Validation F1  |    Test F1     | Validation Accuracy | Test Accuracy  | Validation Balanced Accuracy | Test Balanced Accuracy |\n",
      "+--------------------------+----------------+----------------+---------------------+----------------+------------------------------+------------------------+\n",
      "| Baseline & Mental Stress | 58.59% ± 0.82% | 58.13% ± 0.47% |    55.63% ± 0.06%   | 55.32% ± 0.12% |        55.4% ± 0.07%         |     55.12% ± 0.19%     |\n",
      "+--------------------------+----------------+----------------+---------------------+----------------+------------------------------+------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AdaBoost - {'mental_stress': 1}:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for model in Model:\n",
    "    attempt(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
