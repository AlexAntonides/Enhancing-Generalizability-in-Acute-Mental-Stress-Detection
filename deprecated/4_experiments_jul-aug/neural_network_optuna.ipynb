{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import prepare_model, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'sia.models.wickstrom_2020'\n",
    "# dataset = 'sia.datasets.wickstrom_2020'\n",
    "model = 'sia.models.time_series'\n",
    "dataset = 'sia.datasets.stepping_dataset'\n",
    "\n",
    "data_dir = './data/ecg_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [Path(path).stem for path in glob(f'{data_dir}/*.csv')]\n",
    "train_participants, test_participants = train_test_split(participants[:20], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model.split('.')[-1]\n",
    "model_module = importlib.import_module(model)\n",
    "dataset_module = importlib.import_module(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(baseline = 0, mental_stress = -1, high_physical_activity = -1, moderate_physical_activity = -1, low_physical_activity = -1):\n",
    "    def inner(labels):\n",
    "        baseline_list = ['Sitting', 'Recov1', 'Recov2', 'Recov3', 'Recov4', 'Recov5', 'Recov6']\n",
    "        mental_stress_list = ['TA', 'SSST_Sing_countdown', 'Pasat', 'Raven', 'TA_repeat', 'Pasat_repeat']\n",
    "        high_physical_stress_list = ['Treadmill1', 'Treadmill2', 'Treadmill3', 'Treadmill4', 'Walking_fast_pace', 'Cycling', 'stairs_up_and_down']\n",
    "        moderate_physical_stress_list = ['Walking_own_pace', 'Dishes', 'Vacuum']\n",
    "        low_physical_stress_list = ['Standing', 'Lying_supine', 'Recov_standing']\n",
    "        \n",
    "        def encode_multiclass(label):\n",
    "            if label in baseline_list:\n",
    "                return baseline\n",
    "            elif label in mental_stress_list:\n",
    "                return mental_stress\n",
    "            elif label in high_physical_stress_list:\n",
    "                return high_physical_activity\n",
    "            elif label in moderate_physical_stress_list:\n",
    "                return moderate_physical_activity\n",
    "            elif label in low_physical_stress_list:\n",
    "                return low_physical_activity\n",
    "            else:\n",
    "                return -1\n",
    "            \n",
    "        return {\n",
    "            'label': [encode_multiclass(label) for label in labels],\n",
    "        }\n",
    "    return inner\n",
    "\n",
    "def clean(dataset, mapping={}):\n",
    "    print(\"--- Cleaning ---\")\n",
    "    dataset = dataset.map(\n",
    "        encode(**mapping), \n",
    "        batched=True, \n",
    "        batch_size=2048, \n",
    "        input_columns=['label'],\n",
    "        num_proc=4\n",
    "    )\n",
    "    print(\"--- Filtering ---\")\n",
    "    return dataset.filter(\n",
    "        lambda label: label != -1,\n",
    "        input_columns=['label'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(data_dir, k_fold=5, n_trials=10, mapping = {}):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"epochs\": 11,\n",
    "            \"num_workers\": 8,\n",
    "\n",
    "            \"batch_size\": 100, #trial.suggest_int(\"batch_size\", 10, 1024),\n",
    "            \"learning_rate\": 0.01,\n",
    "\n",
    "            \"window\": 60000 # trial.suggest_int(\"window\", 1000, 60000, step=1000),\n",
    "        }\n",
    "        \n",
    "        wandb.init(\n",
    "            project='stress-in-action',\n",
    "            config={\n",
    "                \"epochs\": params['epochs'],\n",
    "                \"batch_size\": params['batch_size'],\n",
    "                \"learning_rate\": params['learning_rate'],\n",
    "                \"window\": params['window'],\n",
    "                \"architecture\": model_name,\n",
    "                \"dataset\": dataset\n",
    "            }\n",
    "        )\n",
    "\n",
    "        scores = []\n",
    "        for train_indices, val_indices in KFold(n_splits=k_fold, shuffle=True, random_state=42).split(train_participants):\n",
    "            try: \n",
    "                print(\"--- Preparing Model ---\")\n",
    "                model = prepare_model(\n",
    "                    model=model_module.Model, # assuming all models are named Model.\n",
    "                    data=data_dir,\n",
    "                    dataset=dataset_module.Dataset,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    learning_rate=params['learning_rate'],\n",
    "                    num_workers=params['num_workers'],\n",
    "                    ignore_torch_format=True,\n",
    "                    train_participants=[train_participants[i] for i in train_indices],\n",
    "                    val_participants=[train_participants[i] for i in val_indices],\n",
    "                    test_participants=test_participants,\n",
    "                    dataset_kwargs={\n",
    "                        'window': params['window']\n",
    "                    },\n",
    "                    dataset_preprocessor=lambda data: clean(data, mapping)\n",
    "                )\n",
    "\n",
    "                print(\"--- Training ---\")\n",
    "                trainer = train(\n",
    "                    model_name,\n",
    "                    model=model,\n",
    "                    epochs=params['epochs']\n",
    "                )\n",
    "\n",
    "                print(\"--- Done ---\")\n",
    "                scores.append(trainer.callback_metrics[\"val_accuracy\"].item())\n",
    "                break ## only one fold for now\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "        return np.min([np.mean(scores), np.median([scores])])\n",
    "\n",
    "    def detailed(trial):\n",
    "        params = {\n",
    "            \"epochs\": 11,\n",
    "            \"num_workers\": 8,\n",
    "\n",
    "            \"batch_size\": 100, #trial.suggest_int(\"batch_size\", 10, 1024),\n",
    "            \"learning_rate\": 0.01,\n",
    "\n",
    "            \"window\": 60000 # trial.suggest_int(\"window\", 1000, 60000, step=1000),\n",
    "        }\n",
    "        \n",
    "        wandb.init(\n",
    "            project='stress-in-action',\n",
    "            config={\n",
    "                \"epochs\": params['epochs'],\n",
    "                \"batch_size\": params['batch_size'],\n",
    "                \"learning_rate\": params['learning_rate'],\n",
    "                \"window\": params['window'],\n",
    "                \"architecture\": model_name,\n",
    "                \"dataset\": dataset\n",
    "            }\n",
    "        )\n",
    "\n",
    "        scores = []\n",
    "        for train_indices, val_indices in KFold(n_splits=k_fold, shuffle=True, random_state=42).split(train_participants):\n",
    "            try: \n",
    "                model = prepare_model(\n",
    "                    model=model_module.Model, # assuming all models are named Model.\n",
    "                    data=data_dir,\n",
    "                    dataset=dataset_module.Dataset,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    learning_rate=params['learning_rate'],\n",
    "                    num_workers=params['num_workers'],\n",
    "                    ignore_torch_format=True,\n",
    "                    train_participants=[train_participants[i] for i in train_indices],\n",
    "                    val_participants=[train_participants[i] for i in val_indices],\n",
    "                    test_participants=test_participants,\n",
    "                    dataset_kwargs={\n",
    "                        'window': params['window']\n",
    "                    }\n",
    "                )\n",
    "                model.data = clean(model.data, mapping)\n",
    "                trainer = train(\n",
    "                    model_name,\n",
    "                    model=model,\n",
    "                    epochs=params['epochs']\n",
    "                )\n",
    "\n",
    "                trainer.test(model)\n",
    "\n",
    "                scores.append({\n",
    "                    \"val_accuracy\": trainer.callback_metrics[\"val_accuracy\"].item(),\n",
    "                    \"val_precision\": trainer.callback_metrics[\"val_precision\"].item(),\n",
    "                    \"val_f1\": trainer.callback_metrics[\"val_f1\"].item(),\n",
    "                    \"test_accuracy\": trainer.callback_metrics[\"test_accuracy\"].item(),\n",
    "                    \"test_precision\": trainer.callback_metrics[\"test_precision\"].item(),\n",
    "                    \"test_f1\": trainer.callback_metrics[\"test_f1\"].item()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "        return pd.DataFrame(scores)\n",
    "\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=f'{model}_{dataset}_{data_dir}_{str(uuid.uuid4())}',\n",
    "        storage=\"sqlite:///db.sqlite3\",\n",
    "        direction='maximize',\n",
    "        sampler=optuna.samplers.RandomSampler(seed=42)\n",
    "    )\n",
    "\n",
    "    study.optimize(\n",
    "        objective, \n",
    "        n_trials=n_trials,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "\n",
    "    print(\"Best Score:\", best_score)\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    # df = detailed(study.best_trial)\n",
    "\n",
    "    # print(tabulate(\n",
    "    #     [\n",
    "    #         [\n",
    "    #             'Validation F1', \n",
    "    #             'Test F1', \n",
    "    #             'Validation Accuracy', \n",
    "    #             'Test Accuracy', \n",
    "    #             'Validation Balanced Accuracy', \n",
    "    #             'Test Balanced Accuracy'\n",
    "    #         ],\n",
    "    #         [\n",
    "    #             f\"{round(df['val_f1'].mean() * 100, 2)}% ± {round(df['val_f1'].std() * 100, 2)}%\", \n",
    "    #             f\"{round(df['test_f1'].mean() * 100, 2)}% ± {round(df['test_f1'].std() * 100, 2)}%\", \n",
    "    #             f\"{round(df['val_accuracy'].mean() * 100, 2)}% ± {round(df['val_accuracy'].std() * 100, 2)}%\", \n",
    "    #             f\"{round(df['test_accuracy'].mean() * 100, 2)}% ± {round(df['test_accuracy'].std() * 100, 2)}%\", \n",
    "    #             f\"{round(df['val_balanced_accuracy'].mean() * 100, 2)}% ± {round(df['val_balanced_accuracy'].std() * 100, 2)}%\", \n",
    "    #             f\"{round(df['test_balanced_accuracy'].mean() * 100, 2)}% ± {round(df['test_balanced_accuracy'].std() * 100, 2)}%\"\n",
    "    #         ],\n",
    "    #     ], tablefmt='fancy_grid')\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-21 14:12:54,413] A new study created in RDB with name: sia.models.time_series_sia.datasets.stepping_dataset_./data/ecg_model_5bf51f8d-5f17-4fcd-8b1b-3d3e49b94098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4204c65e98804d6abeda6b2cbea2e37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malex-antonides\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\university\\thesis_old\\wandb\\run-20240721_141256-meov1fpv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alex-antonides/stress-in-action/runs/meov1fpv' target=\"_blank\">apricot-mountain-294</a></strong> to <a href='https://wandb.ai/alex-antonides/stress-in-action' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alex-antonides/stress-in-action' target=\"_blank\">https://wandb.ai/alex-antonides/stress-in-action</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alex-antonides/stress-in-action/runs/meov1fpv' target=\"_blank\">https://wandb.ai/alex-antonides/stress-in-action/runs/meov1fpv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing Model ---\n",
      "--- Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cleaning ---\n",
      "--- Filtering ---\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                 | Type            | Params\n",
      "----------------------------------------------------------\n",
      "0  | rnn                  | LSTM            | 14.4 M\n",
      "1  | fc                   | Linear          | 61    \n",
      "2  | dropout              | Dropout         | 0     \n",
      "3  | batch_norm           | BatchNorm1d     | 120   \n",
      "4  | train_accuracy       | BinaryAccuracy  | 0     \n",
      "5  | train_f1score        | BinaryF1Score   | 0     \n",
      "6  | train_precision      | BinaryPrecision | 0     \n",
      "7  | validation_accuracy  | BinaryAccuracy  | 0     \n",
      "8  | validation_f1score   | BinaryF1Score   | 0     \n",
      "9  | validation_precision | BinaryPrecision | 0     \n",
      "10 | test_accuracy        | BinaryAccuracy  | 0     \n",
      "11 | test_f1score         | BinaryF1Score   | 0     \n",
      "12 | test_precision       | BinaryPrecision | 0     \n",
      "----------------------------------------------------------\n",
      "14.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.4 M    Total params\n",
      "57.660    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f703095e41848c68913f0a2672ad5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea15f9308a84b6ca26ef61b91cb5aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Done ---\n",
      "'val_accuracy'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9918030770145a5b1104accf4fa35df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-mountain-294</strong> at: <a href='https://wandb.ai/alex-antonides/stress-in-action/runs/meov1fpv' target=\"_blank\">https://wandb.ai/alex-antonides/stress-in-action/runs/meov1fpv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240721_141256-meov1fpv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2024-07-21 14:14:47,294] Trial 0 failed with parameters: {} because of the following error: The value nan is not acceptable.\n",
      "[W 2024-07-21 14:14:47,295] Trial 0 failed with value nan.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Record does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/ecg_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmental_stress\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 145\u001b[0m, in \u001b[0;36moptimize\u001b[1;34m(data_dir, k_fold, n_trials, mapping)\u001b[0m\n\u001b[0;32m    138\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m    139\u001b[0m     objective, \n\u001b[0;32m    140\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    141\u001b[0m     show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    142\u001b[0m )\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params\u001b[49m\n\u001b[0;32m    146\u001b[0m best_score \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_value\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_score)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:114\u001b[0m, in \u001b[0;36mStudy.best_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbest_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return parameters of the best trial in the study.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m \n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_trial\u001b[49m\u001b[38;5;241m.\u001b[39mparams\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:157\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\storages\\_cached_storage.py:182\u001b[0m, in \u001b[0;36m_CachedStorage.get_best_trial\u001b[1;34m(self, study_id)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_best_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, study_id: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrozenTrial:\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py:913\u001b[0m, in \u001b[0;36mRDBStorage.get_best_trial\u001b[1;34m(self, study_id)\u001b[0m\n\u001b[0;32m    910\u001b[0m direction \u001b[38;5;241m=\u001b[39m _directions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m direction \u001b[38;5;241m==\u001b[39m StudyDirection\u001b[38;5;241m.\u001b[39mMAXIMIZE:\n\u001b[1;32m--> 913\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrialModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_max_value_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     trial \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mTrialModel\u001b[38;5;241m.\u001b[39mfind_min_value_trial(study_id, \u001b[38;5;241m0\u001b[39m, session)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\storages\\_rdb\\models.py:214\u001b[0m, in \u001b[0;36mTrialModel.find_max_value_trial\u001b[1;34m(cls, study_id, objective, session)\u001b[0m\n\u001b[0;32m    195\u001b[0m trial \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    196\u001b[0m     session\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mstudy_id \u001b[38;5;241m==\u001b[39m study_id)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;241m.\u001b[39mone_or_none()\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(NOT_FOUND_MSG)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\n",
      "\u001b[1;31mValueError\u001b[0m: Record does not exist."
     ]
    }
   ],
   "source": [
    "optimize('./data/ecg_model', k_fold=2, n_trials=1, mapping={ 'mental_stress': 1 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
