{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The training process is defined in this notebook. Throughout the project, two processes are used, the part that trains and optimizes the machine learning models, and the part that trains and optimizes the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './data/features/'\n",
    "participants = [Path(p).stem for p in glob(f'{root_dir}/*.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participant Split\n",
    "The step defined below splits the participants into their respective buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bucket, test_bucket = train_test_split(participants, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Models\n",
    "The step defined trains and optimizes the machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Enum):\n",
    "    DecisionTree = 1\n",
    "    RandomForest = 2 \n",
    "    AdaBoost = 3\n",
    "    LinearDiscriminantAnalysis = 4\n",
    "    KNearestNeighbors = 5\n",
    "    LogisticRegression = 6\n",
    "    XGBoost = 7\n",
    "    QuadraticDiscriminantAnalysis = 8\n",
    "    RandomBaseline = 9\n",
    "    SophisticatedBaseline = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding\n",
    "The step defined encodes the data for the machine learning models. This allows the user to train a model targeting a specific category (i.e. Baseline versus Mental Stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(baseline = 0, mental_stress = -1, high_physical_activity = -1, moderate_physical_activity = -1, low_physical_activity = -1):\n",
    "    \"\"\"Encode the categories into integers based on a given mapping. Any -1 is discarded.\"\"\"\n",
    "    def inner(categories):\n",
    "        def encode_class(label):\n",
    "            if label == 'baseline':\n",
    "                return baseline\n",
    "            elif label == 'mental_stress':\n",
    "                return mental_stress\n",
    "            elif label == 'high_physical_activity':\n",
    "                return high_physical_activity\n",
    "            elif label == 'moderate_physical_activity':\n",
    "                return moderate_physical_activity\n",
    "            elif label == 'low_physical_activity':\n",
    "                return low_physical_activity\n",
    "            else:\n",
    "                return -1\n",
    "            \n",
    "        return {\n",
    "            'label': [encode_class(category) for category in categories],\n",
    "        }\n",
    "    return inner\n",
    "\n",
    "def clean(dataset, mapping={}):\n",
    "    \"\"\"Clean the dataset by encoding category and removing any -1 labels.\"\"\"\n",
    "    dataset = dataset.map(\n",
    "        encode(**mapping), \n",
    "        batched=True, \n",
    "        batch_size=2048, \n",
    "        input_columns=['category'],\n",
    "        num_proc=8\n",
    "    )\n",
    "    return dataset.filter(\n",
    "        lambda label: label != -1,\n",
    "        input_columns=['category'],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "The method below defines the step used to train a given model and calculate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model:int, \n",
    "    data_dir: str,\n",
    "    X_labels: list[str],\n",
    "    y_label: str, \n",
    "    train_bucket: list[str], \n",
    "    val_bucket: list[str], \n",
    "    test_bucket: list[str], \n",
    "    params: dict,\n",
    "    mapping: dict = {}\n",
    "):\n",
    "    \"\"\"Train a model using the given dataset and parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: int\n",
    "        The model to use. Unfortunately, the enum Model can't be passed over the network, thus a number is used.\n",
    "        1: DecisionTree\n",
    "        2: RandomForest\n",
    "        3: AdaBoost\n",
    "        4: LinearDiscriminantAnalysis\n",
    "        5: KNearestNeighbors\n",
    "        6: LogisticRegression\n",
    "        7: XGBoost\n",
    "        8: QuadraticDiscriminantAnalysis\n",
    "        9: RandomBaseline\n",
    "        10: SophisticatedBaseline\n",
    "    data_dir: str\n",
    "        The directory containing the dataset.\n",
    "    X_labels: list[str]\n",
    "        The features to use.\n",
    "    y_label: str\n",
    "        The target label.\n",
    "    train_bucket: list[str]\n",
    "        The participants to use for training.\n",
    "    val_bucket: list[str]\n",
    "        The participants to use for validation.\n",
    "    test_bucket: list[str]\n",
    "        The participants to use for testing.\n",
    "    params: dict\n",
    "        The hyperparameters for the model.\n",
    "    mapping: dict\n",
    "        The mapping for the categories.\n",
    "    \"\"\"\n",
    "    dataset = datasets.load_dataset(\n",
    "        data_dir, \n",
    "        train_participants=train_bucket,\n",
    "        val_participants=val_bucket,\n",
    "        test_participants=test_bucket,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    dataset = dataset.select_columns([y_label] + X_labels)\n",
    "    dataset = clean(dataset, mapping=mapping)\n",
    "    \n",
    "    train = dataset['fit'].to_pandas().replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "    X_train, y_train = train[X_labels], train[y_label]\n",
    "    del train\n",
    "\n",
    "    if model == 1:\n",
    "        cls = sklearn.tree.DecisionTreeClassifier(**params, random_state=42)\n",
    "    elif model == 2:\n",
    "        cls = sklearn.ensemble.RandomForestClassifier(**params, random_state=42, bootstrap=False)\n",
    "    elif model == 3:\n",
    "        cls = sklearn.ensemble.AdaBoostClassifier(base_estimator=sklearn.tree.DecisionTreeClassifier(criterion='entropy', min_samples_split=20), **params)\n",
    "    elif model == 4:\n",
    "        cls = sklearn.discriminant_analysis.LinearDiscriminantAnalysis(**params)\n",
    "    elif model == 5:\n",
    "        cls = sklearn.neighbors.KNeighborsClassifier(**params)\n",
    "    elif model == 6:\n",
    "        cls = sklearn.linear_model.LogisticRegression(**params)\n",
    "    elif model == 7:\n",
    "        cls = xgboost.XGBClassifier(**params)\n",
    "    elif model == 8:\n",
    "        cls = sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis(**params)\n",
    "    elif model == 9:\n",
    "        cls = sklearn.dummy.DummyClassifier(strategy= 'uniform', random_state= 42, **params)\n",
    "    elif model == 10:\n",
    "        cls = sklearn.dummy.DummyClassifier(strategy= 'stratified', random_state= 42, **params)\n",
    "    else: \n",
    "        raise ValueError('Invalid model')\n",
    "\n",
    "    cls.fit(X_train, y_train)\n",
    "\n",
    "    del X_train\n",
    "\n",
    "    val = dataset['validate'].to_pandas().replace([np.inf, -np.inf, np.nan], 0)\n",
    "    X_val, y_val = val[X_labels], val[y_label]\n",
    "    del val\n",
    "\n",
    "    test = dataset['test'].to_pandas().replace([np.inf, -np.inf, np.nan], 0)\n",
    "    X_test, y_test = test[X_labels], test[y_label]\n",
    "    del test\n",
    "\n",
    "    data = {\n",
    "        'val_accuracy': sklearn.metrics.accuracy_score(y_val, cls.predict(X_val)),\n",
    "        'val_balanced_accuracy': sklearn.metrics.balanced_accuracy_score(y_val, cls.predict(X_val)),\n",
    "        'test_accuracy': sklearn.metrics.accuracy_score(y_test, cls.predict(X_test)),\n",
    "        'test_balanced_accuracy': sklearn.metrics.balanced_accuracy_score(y_test, cls.predict(X_test)),\n",
    "    }\n",
    "\n",
    "    if len(y_train.unique()) == 2:\n",
    "        ## binary\n",
    "        data['val_f1'] = sklearn.metrics.f1_score(y_val, cls.predict(X_val))\n",
    "        data['test_f1'] = sklearn.metrics.f1_score(y_test, cls.predict(X_test))\n",
    "\n",
    "        # AUC\n",
    "        data['val_auc'] = sklearn.metrics.roc_auc_score(y_val, cls.predict_proba(X_val)[:, 1])\n",
    "        data['test_auc'] = sklearn.metrics.roc_auc_score(y_test, cls.predict_proba(X_test)[:, 1])\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        val_cm = sklearn.metrics.confusion_matrix(y_val, cls.predict(X_val), labels=y_train.unique())\n",
    "        test_cm = sklearn.metrics.confusion_matrix(y_test, cls.predict(X_test), labels=y_train.unique())\n",
    "\n",
    "        data['val_cm'] = val_cm\n",
    "        data['test_cm'] = test_cm\n",
    "    else: \n",
    "        # multiclass\n",
    "        data['val_f1'] = sklearn.metrics.f1_score(y_val, cls.predict(X_val), average='micro')\n",
    "        data['test_f1'] = sklearn.metrics.f1_score(y_test, cls.predict(X_test), average='micro')\n",
    "\n",
    "        # AUC (one-vs-rest)\n",
    "        y_val_bin = sklearn.preprocessing.label_binarize(y_val, classes=np.unique(y_train))\n",
    "        y_test_bin = sklearn.preprocessing.label_binarize(y_test, classes=np.unique(y_train))\n",
    "        \n",
    "        val_auc = sklearn.metrics.roc_auc_score(y_val_bin, cls.predict_proba(X_val), average='macro', multi_class='ovr')\n",
    "        test_auc = sklearn.metrics.roc_auc_score(y_test_bin, cls.predict_proba(X_test), average='macro', multi_class='ovr')\n",
    "        \n",
    "        data['val_auc'] = val_auc\n",
    "        data['test_auc'] = test_auc\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        val_cm = sklearn.metrics.confusion_matrix(y_val, cls.predict(X_val), labels=y_train.unique())\n",
    "        test_cm = sklearn.metrics.confusion_matrix(y_test, cls.predict(X_test), labels=y_train.unique())\n",
    "\n",
    "        data['val_cm'] = val_cm\n",
    "        data['test_cm'] = test_cm\n",
    "\n",
    "    del y_train, X_val, y_val\n",
    "    \n",
    "    if model == 2:\n",
    "        importances = cls.feature_importances_\n",
    "        feature_importance = pd.DataFrame(importances, index=X_labels, columns=[\"importance\"])\n",
    "        feature_importance[\"std\"] = np.std([tree.feature_importances_ for tree in cls.estimators_], axis=0)\n",
    "        feature_importance.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "        result = sklearn.inspection.permutation_importance(\n",
    "            cls, X_test, y_test, n_repeats=10, random_state=42\n",
    "        )\n",
    "        permutation_importances = pd.DataFrame(result.importances_mean, index=X_labels, columns=[\"importance\"])\n",
    "        permutation_importances[\"std\"] = result.importances_std\n",
    "        permutation_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "        data['feature_importance'] = feature_importance[\"importance\"].head(5)\n",
    "        data['fi_std'] = feature_importance[\"std\"].head(5)\n",
    "        data['permutation_importances'] = permutation_importances[\"importance\"].head(5)\n",
    "        data['pi_std'] = permutation_importances[\"std\"].head(5)\n",
    "\n",
    "    del X_test, y_test\n",
    "\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization\n",
    "The step below optimizes the model using the Optuna library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(\n",
    "    model: Model, \n",
    "    data_directory: str, \n",
    "    X_labels: list[str], \n",
    "    y_label: str, \n",
    "    train_bucket: list[str], \n",
    "    test_bucket: list[str],\n",
    "    k_fold: int = 10, \n",
    "    mapping: dict = {}, \n",
    "    params: dict = None\n",
    "):\n",
    "    \"\"\"Optimize the model using Optuna.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Model\n",
    "        The model to use.\n",
    "    data_directory: str\n",
    "        The directory containing the dataset.\n",
    "    X_labels: list[str]\n",
    "        The features to use.\n",
    "    y_label: str\n",
    "        The target label.\n",
    "    train_bucket: list[str]\n",
    "        The participants to use for training.\n",
    "    test_bucket: list[str]\n",
    "        The participants to use for testing.\n",
    "    k_fold: int\n",
    "        The number of folds to use.\n",
    "    mapping: dict\n",
    "        The mapping for the categories.\n",
    "    params: dict\n",
    "        The hyperparameters for the\n",
    "    \"\"\"\n",
    "    skip_optimization = params is not None\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.title = f'{model.name}'\n",
    "    table.field_names = [\n",
    "        '',\n",
    "        'Test F1', \n",
    "        'Test Accuracy', \n",
    "        'Test AUC'\n",
    "    ]\n",
    "    model_value = int(model.value)\n",
    "\n",
    "    def objective(trial):\n",
    "        if model == Model.DecisionTree:\n",
    "            params = {\n",
    "                'max_depth': trial.suggest_int('max_depth', 1, 32),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "            }\n",
    "        elif model == Model.RandomForest:\n",
    "            params = {\n",
    "                \"n_estimators\": 500,\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "                \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 10, 200, step=10),\n",
    "                \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 3, 15),\n",
    "            }\n",
    "        elif model == Model.AdaBoost:\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1.0),\n",
    "            }\n",
    "        elif model == Model.XGBoost:\n",
    "            params = {\n",
    "                'max_depth': trial.suggest_int('max_depth', 1, 16),\n",
    "                'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1.0),\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 10, 300),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "            }\n",
    "        elif model == Model.LogisticRegression:\n",
    "            params = {\n",
    "                'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n",
    "                'solver': trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "                'max_iter': trial.suggest_int('max_iter', 100, 1000),\n",
    "            }\n",
    "        elif model == Model.KNearestNeighbors:\n",
    "            params = {\n",
    "                'n_neighbors': trial.suggest_int('n_neighbors', 1, 50),\n",
    "                'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "                'p': trial.suggest_int('p', 1, 2),\n",
    "            }\n",
    "        elif model == Model.LinearDiscriminantAnalysis:\n",
    "            params = {\n",
    "                'solver': trial.suggest_categorical('solver', ['lsqr', 'eigen']),\n",
    "                'shrinkage': trial.suggest_uniform('shrinkage', 0.0, 1.0),\n",
    "            }\n",
    "        elif model == Model.QuadraticDiscriminantAnalysis:\n",
    "            params = {\n",
    "                'reg_param': trial.suggest_uniform('reg_param', 0.0, 1.0),\n",
    "            }\n",
    "        else: \n",
    "            raise ValueError('Invalid model')\n",
    "\n",
    "        scores = Parallel(n_jobs=8)(delayed(train)(\n",
    "            model_value, \n",
    "            data_directory,\n",
    "            X_labels, \n",
    "            y_label, \n",
    "            [train_bucket[i] for i in train_indices], \n",
    "            [train_bucket[i] for i in val_indices], \n",
    "            test_bucket, \n",
    "            params,\n",
    "            mapping=mapping\n",
    "        ) for train_indices, val_indices in sklearn.model_selection.KFold(n_splits=k_fold, shuffle=True, random_state=42).split(train_bucket)) \n",
    "        df = pd.DataFrame(scores)\n",
    "        return np.mean([df['test_auc'].mean(), df['test_auc'].median()])\n",
    "    \n",
    "    def detailed(params): \n",
    "        scores = Parallel(n_jobs=8)(delayed(train)(\n",
    "            model_value, \n",
    "            data_directory,\n",
    "            X_labels, \n",
    "            y_label, \n",
    "            [train_bucket[i] for i in train_indices], \n",
    "            [train_bucket[i] for i in val_indices], \n",
    "            test_bucket, \n",
    "            params,\n",
    "            mapping=mapping\n",
    "        ) for train_indices, val_indices in sklearn.model_selection.KFold(n_splits=k_fold, shuffle=True, random_state=42).split(train_bucket)) \n",
    "        return pd.DataFrame(scores)\n",
    "\n",
    "    if skip_optimization == False:\n",
    "        study = optuna.create_study(\n",
    "            study_name=f'{model.name}_{data_directory}_{str(uuid.uuid4())}',\n",
    "            storage=\"sqlite:///db.sqlite3\",\n",
    "            direction='maximize',\n",
    "            sampler=optuna.samplers.RandomSampler(seed=42)\n",
    "        )\n",
    "\n",
    "        study.optimize(\n",
    "            objective, \n",
    "            n_trials=50,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "    \n",
    "        # Get the best hyperparameters\n",
    "        best_params = study.best_params\n",
    "        best_score = study.best_value\n",
    "\n",
    "        print(\"Best Score:\", best_score)\n",
    "        print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    if skip_optimization:\n",
    "        print(\"Skipping optimization, using given parameters...\", best_params)\n",
    "        best_params = params\n",
    "\n",
    "    df = detailed(best_params)\n",
    "\n",
    "    titles = []\n",
    "    if (\"baseline\" not in mapping) or (mapping[\"baseline\"] != -1):\n",
    "        titles.append(\"Baseline\")\n",
    "    if \"mental_stress\" in mapping and mapping[\"mental_stress\"] >= 0:\n",
    "        titles.append(\"Mental Stress\")\n",
    "    if \"low_physical_activity\" in mapping and mapping[\"low_physical_activity\"] >= 0:\n",
    "        titles.append(\"Low Physical Activity\")\n",
    "    if \"moderate_physical_activity\" in mapping and mapping[\"moderate_physical_activity\"] >= 0:\n",
    "        titles.append(\"Moderate Physical Activity\")\n",
    "    if \"high_physical_activity\" in mapping and mapping[\"high_physical_activity\"] >= 0:\n",
    "        titles.append(\"High Physical Activity\")\n",
    "        \n",
    "    row = [\n",
    "        f\"{' & '.join(titles)}\",\n",
    "        f\"{round(df['test_f1'].mean() * 100, 2)}% ± {round(df['test_f1'].std() * 100, 2)}%\", \n",
    "        f\"{round(df['test_accuracy'].mean() * 100, 2)}% ± {round(df['test_accuracy'].std() * 100, 2)}%\", \n",
    "        f\"{round(df['test_auc'].mean() * 100, 2)}% ± {round(df['test_auc'].std() * 100, 2)}%\"\n",
    "    ]\n",
    "    table.add_row(row)\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features\n",
    "The resulting features described in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels =  [\n",
    "    # Time-Domain\n",
    "    \"hr_mean\",\n",
    "    \"hr_std\",\n",
    "    \"hr_min\",\n",
    "    \"hr_max\",\n",
    "    \"hrv_mean\",\n",
    "    \"hrv_std\",\n",
    "    \"hrv_rms\",\n",
    "    \"avnn\",\n",
    "    \"sdnn\"\n",
    "    \"nn20\",\n",
    "    \"pnn20\",\n",
    "    \"nn50\",\n",
    "    \"pnn50\",\n",
    "    \"cvnn\",\n",
    "    \"cvsd\",\n",
    "\n",
    "    # Frequency-Domain\n",
    "    \"ulf_min\",\n",
    "    \"ulf_max\",\n",
    "    \"ulf_mean\",\n",
    "    \"ulf_std\",\n",
    "    \"ulf_power\",\n",
    "    \"ulf_covariance\",\n",
    "    \"ulf_energy\",\n",
    "    \"ulf_entropy\",\n",
    "    \"vlf_min\",\n",
    "    \"vlf_max\",\n",
    "    \"vlf_mean\",\n",
    "    \"vlf_std\",\n",
    "    \"vlf_power\",\n",
    "    \"vlf_covariance\",\n",
    "    \"vlf_energy\",\n",
    "    \"vlf_entropy\",\n",
    "    \"lf_min\",\n",
    "    \"lf_max\",\n",
    "    \"lf_mean\",\n",
    "    \"lf_std\",\n",
    "    \"lf_power\",\n",
    "    \"lf_covariance\",\n",
    "    \"lf_energy\",\n",
    "    \"lf_entropy\",\n",
    "    \"hf_min\",   \n",
    "    \"hf_max\",\n",
    "    \"hf_mean\",\n",
    "    \"hf_std\",\n",
    "    \"hf_power\",\n",
    "    \"hf_covariance\",\n",
    "    \"hf_energy\",\n",
    "    \"hf_entropy\",\n",
    "    \"vhf_min\",\n",
    "    \"vhf_max\",\n",
    "    \"vhf_mean\",\n",
    "    \"vhf_std\",\n",
    "    \"vhf_power\",\n",
    "    \"vhf_covariance\",\n",
    "    \"vhf_energy\",\n",
    "    \"vhf_entropy\",\n",
    "    \"uhf_min\",\n",
    "    \"uhf_max\",\n",
    "    \"uhf_mean\",\n",
    "    \"uhf_std\",\n",
    "    \"uhf_power\",\n",
    "    \"uhf_covariance\",\n",
    "    \"uhf_energy\",\n",
    "    \"uhf_entropy\",\n",
    "    \"tp_power\",\n",
    "    \"lp_ulf_power\",\n",
    "    \"lp_vlf_power\",\n",
    "    \"lp_lf_power\",\n",
    "    \"lp_hf_power\",\n",
    "    \"lp_vhf_power\",\n",
    "    \"lp_uhf_power\",\n",
    "    \"lf_hf_power\",\n",
    "\n",
    "    # Nonlinear\n",
    "    \"apen\",\n",
    "    \"sampen\",\n",
    "    \"fuzzyen\",\n",
    "    \"sd1\",\n",
    "    \"sd2\",\n",
    "    \"sd1_sd2\",\n",
    "    \"pss\",\n",
    "    \"w\",\n",
    "    \"wmax\",\n",
    "    \"wen\",\n",
    "\n",
    "    # Morphology\n",
    "    \"twa\"\n",
    "]\n",
    "y_label = \"category\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Optimization\n",
    "The step below optimizes the hyper-parameters of the model using the Optuna library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove the comment below to start the optimization process and to find the best hyper-parameters for the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in [\n",
    "#     Model.DecisionTree,\n",
    "#     Model.RandomForest,\n",
    "#     Model.AdaBoost,\n",
    "#     Model.XGBoost,\n",
    "#     Model.LogisticRegression,\n",
    "#     Model.KNearestNeighbors, \n",
    "#     Model.LinearDiscriminantAnalysis,\n",
    "#     Model.QuadraticDiscriminantAnalysis,\n",
    "#     Model.RandomBaseline,\n",
    "#     Model.SophisticatedBaseline,\n",
    "# ]:\n",
    "#     for mapping in [\n",
    "#         { \"mental_stress\": 1 },                                              # Baseline versus Mental Stress\n",
    "#         { \"high_physical_activity\": 1 },                                     # Baseline versus High Physical Activity\n",
    "#         { \"baseline\": -1, \"mental_stress\": 0, \"high_physical_activity\": 1 }, # Mental Stress versus High Physical Activity\n",
    "#         { \"mental_stress\": 1, \"high_physical_activity\": 2 },                 # Baseline versus Mental Stress versus High Physical Activity\n",
    "#     ]:\n",
    "#         optimize(\n",
    "#             model, \n",
    "#             root_dir, \n",
    "#             X_labels,\n",
    "#             y_label,\n",
    "#             train_bucket, \n",
    "#             test_bucket,\n",
    "#             mapping=mapping\n",
    "#         )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given that we already found the perfect hyper-parameters, we will not run the optimization process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, params in [\n",
    "    (Model.DecisionTree, {'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 15}),\n",
    "    (Model.RandomForest, {'max_depth': 8, 'min_samples_split': 50, 'max_features': 5}),\n",
    "    (Model.AdaBoost, {'n_estimators': 100}),\n",
    "    (Model.XGBoost, {'max_depth': 7, 'learning_rate': 0.007476312062252299, 'n_estimators': 188, 'min_child_weight': 2, 'subsample': 0.6460723242676091, 'colsample_bytree': 0.6831809216468459}),\n",
    "    (Model.LogisticRegression, {'C': 0.05564180225431373, 'solver': 'newton-cg', 'max_iter': 152}),\n",
    "    (Model.KNearestNeighbors, {'n_neighbors': 9}),\n",
    "    (Model.LinearDiscriminantAnalysis, {'solver': 'lsqr', 'shrinkage': 0.15599452033620265}),\n",
    "    (Model.QuadraticDiscriminantAnalysis, {'reg_param': 0.16}),\n",
    "    (Model.RandomBaseline, {}),\n",
    "    (Model.SophisticatedBaseline, {}),\n",
    "]:\n",
    "    for mapping in [\n",
    "        { \"mental_stress\": 1 },                                              # Baseline versus Mental Stress\n",
    "        { \"high_physical_activity\": 1 },                                     # Baseline versus High Physical Activity\n",
    "        { \"baseline\": -1, \"mental_stress\": 0, \"high_physical_activity\": 1 }, # Mental Stress versus High Physical Activity\n",
    "        { \"mental_stress\": 1, \"high_physical_activity\": 2 },                 # Baseline versus Mental Stress versus High Physical Activity\n",
    "    ]:\n",
    "        optimize(\n",
    "            model, \n",
    "            root_dir, \n",
    "            X_labels,\n",
    "            y_label,\n",
    "            train_bucket, \n",
    "            test_bucket,\n",
    "            mapping=mapping,\n",
    "            params=params\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "The step defined trains and optimizes the deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import prepare\n",
    "from src.models import RnnModule\n",
    "from src.datamodules import MultiParticipantDataModule\n",
    "from src.datasets import WindowedDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For this experiment, the K-Fold and Hyper-parameter optimization is removed, thus we split the data into training and validation sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bucket, validation_bucket = train_test_split(train_bucket, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is a combination between a module that tracks metrics, and a model defined in src/models/*\n",
    "model = prepare(RnnModule)\n",
    "\n",
    "# Datamodule is a combination between a dataset that is capable of loading multiple participants, \n",
    "# and a dataset defined in src/datasets/*.\n",
    "datamodule = MultiParticipantDataModule(\n",
    "    f'{root_dir}', \n",
    "    train_bucket, \n",
    "    validation_bucket, \n",
    "    test_bucket, \n",
    "    batch_size=64,\n",
    "    dataset=WindowedDataset,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=15),\n",
    "    ModelCheckpoint(save_top_k=1, monitor=\"val_BinaryAccuracy\", mode=\"max\", save_last=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=100, \n",
    "    callbacks=callbacks,\n",
    "    accelerator=\"auto\", \n",
    "    devices=\"auto\", \n",
    "    strategy=\"auto\", \n",
    "    profiler=\"simple\",\n",
    "    default_root_dir=f\"./checkpoints/{type(model).__name__}\",\n",
    "    logger=L.pytorch.loggers.WandbLogger(\n",
    "        project=\"stress-in-action\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = L.pytorch.tuner.Tuner(\n",
    "    trainer\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    datamodule=datamodule\n",
    ")\n",
    "\n",
    "trainer.test(\n",
    "    ckpt_path=\"best\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
